# Applications

In this chapter, we will bring some applications based on real data
sets to show how use R packages to analyse count data.

## Cotton Bolls

Cotton production can be drastically reduced by attack of defoliating
insects. Depending on the growth stage, the plant can recover from the
caused damage and keeps production not affected or can have the
production reduced by low intensity defoliation.

A greenhouse experiment with cotton plants (*Gossypium hirsutum*) was
done under a completely randomized design with five replicates to assess
the effects of five defoliation levels (0%, 25%, 50%,75% and 100%) on
the observed number of bolls produced by plants at five growth stages:
vegetative, flower-bud, blossom, fig and cotton boll. The experimental
unity was a pot with two plants [@Silva2012a, for more]. The number of
cotton bolls was recorded at the hasvest of the experiment.

```{r, message = FALSE}
library(lattice)
library(latticeExtra)
library(gridExtra)
library(plyr)
library(car)
library(corrplot)
library(doBy)
library(multcomp)
library(mcglm)
library(MRDCr)
ls("package:MRDCr")
```
```{r, eval = FALSE}
# Documentation in Portuguese.
help(capdesfo, help_type = "html")
```
```{r}
str(capdesfo)
levels(capdesfo$est) <- c("vegetative",
                          "flower-bud",
                          "blossom",
                          "fig",
                          "cotton boll")
xtabs(~est + des, data = capdesfo)
```

Figure \@ref(fig:bools-mean-var) (top) shows the beeswarm plot of number
of cotton bolls recorded for each combination of defoliation level and
growth stage. All the points in the sample means and variances
dispersion diagram (bottom) are below the identity line, clearly
suggesting data with underdispersion.

```{r bools-mean-var, fig.cap = cap, echo = FALSE, fig.height = 10}
cap <- "(top) Number of bolls produced for each artificial defoliation level and each growth stage. (bottom) Sample variance against the sample mean of the five replicates for each combination of defoliation level and growth stage."

xy1 <- xyplot(ncap ~ des | est,
              data = capdesfo,
              layout = c(NA, 2),
              type = c("p", "smooth"),
              xlab = "Artifitial defoliation levels",
              ylab = "Bolls produced",
              as.table = TRUE,
              grid = TRUE,
              xlim = extendrange(c(0:1), f = 0.15),
              panel = panel.beeswarm,
              spread = 0.05)

mv <- aggregate(ncap ~ est + des, data = capdesfo,
                FUN = function(x) c(mean = mean(x), var = var(x)))
xlim <- ylim <- extendrange(c(mv$ncap), f = 0.05)

xy2 <- xyplot(ncap[, "var"] ~ ncap[, "mean"],
              data = mv,
              xlim = xlim,
              ylim = ylim,
              ylab = "Sample variance",
              xlab = "Sample mean",
              panel = function(x, y) {
                  panel.xyplot(x, y, type = c("p", "r"), grid = TRUE)
                  panel.abline(a = 0, b = 1, lty = 2)
              })

grid.arrange(xy1, xy2, ncol = 1)
```

The exploratory data analysis, although simple, was able to detect
departures from the Poisson equidispersion assumption. So, we have in
advance few conditions met for the use of GLM Poisson as a regression
model to analyse this experiment.

Poisson, as being a process derived from the memoryless waiting times
Exponential distribuition, implies that each boll is an independent
event in the artificial subjacent domain, that can be thought was the
natural resource domain that the plant has to allocate bolls. Its is
easy to assume, based on plant fisiology, that the probability of a boll
decreases with the number of previous bolls because the plant's resource
to produce bolls is limited and it is a non memoryless process
equivalent.

<!--

We are going to convert artifitial defoliation (`desf`) to categorial,
despite is a numeric factor, to avoid lack of fit concerns that are out
of scope here.

-->

<!--

To access the effects of the experimental factors, nested models in
terms of linear predictors were fitted, as described by the following
structures for the log-link function $g()$.

  1. $g(\mu) = \beta_0$ (null model);
  2. $g(\mu) = \beta_0 + \beta_1 \text{def}$ (1st order effect of
     defoliation);
  3. $g(\mu) = \beta_0 + \beta_1 \text{def} + \beta_2 \text{def}^2$
     (2nd order effect of defoliation);
  4. $g(\mu) = \beta_0 + \beta_{1j} \text{def} + \beta_2
     \text{def}^2$ (1st order defoliation effect for each growth stage);
  5. $g(\mu) = \beta_0 + \beta_{1j} \text{def}
     + \beta_{2j} \text{def}^2$ (2nd order effect defoliation for each
     growth stage).

-->

Based on the exploratory data analysis, a predictor with 2nd order
effect of defoliation for each growth stage should be enough to model
the number of bolls mean in a regression model. The analysis and
assessment of the effects of the experimental factors are based on the
Poisson, Gamma-count and Poisson Tweedie models.

```{r}
m0 <- glm(ncap ~ est * (des + I(des^2)),
          data = capdesfo,
          family = poisson)

summary(m0)
logLik(m0)
```
```{r, include = FALSE}
rdev <- round(deviance(m0), 2)
rdf <- df.residual(m0)
rat <- rdev/rdf
```

We fit the GLM Poisson regression model using the stardard `glm()`
function in R. The fitted model summary shows the estimated parameters
for the second order effect of defoliation crossed with growth stages
levels. The residual deviance was `r rdev` based on `r rdf` degrees of
freedoom. The ratio $`r rdev`/`r rdf` = `r rat`$ is a strong evidence
against Poisson equidispersion assumption that uses a dispersion
parameter equals 1.

```{r}
anova(m0, test = "Chisq")
```

The analysis of deviance table did not stated effect of any
interactions, neither second order effect of defiliation. Although, all
these effects are noticeable in Figure \@ref(bools-mean-var).

```{r bolls-plot-residuals, echo = FALSE, fig.cap = cap, fig.height = 7}
cap <-
    "The 4 plots for checking departures of assumptions in the GLM-Poisson regression model for the number of cotton bolls."
par(mfrow = c(2, 2))
plot(m0); layout(1)
```

Figure \@ref(bolls-plot-residuals) displays the four residual plots for
the fitted model. Based on these plots, there is no concern about
mispecifications regarding to the model predictor or influential
observations.  The only remarkable aspect is about the range of the
stardartized deviance residuals quite distant from the expected -3 to 3
from the normal distribution. Once more, these is another measure
indicating a underdispersed count data.

The `gcnt()` is a function defined in the `MRDCr` package [@mrdcr-pkg]
to fit the Gamma-Count regression model. This function fits a
GML-Poisson to use the estimates as initial values to optimize
Gamma-Count likelihood using `optim()` through `bblme` package
[@bblme-pkg].

```{r}
m1 <- gcnt(ncap ~ est * (des + I(des^2)),
           data = capdesfo)
summary(m1)
```

During the optimization process for this dataset, `optim()` has found
`NaN` when evaluating the likelihood. This occurs due little numerical
precision to calculate the difference of Gamma CDFs on tails or for
extreme values, resulting in numerical zeros and corresponding `-Inf`
log-likelihood. This is a numerical problem that can narrow, or make
things difficult, the use of Gamma-Count regression model.

The dispersion parameter is the first position in the parameter
vector. The optimization was carried out on the log scale to avoid
problems regarding to bounded parameter spaces.  As the dispersion
parameter is in fact interpreted as a precision coefficient, the
positive estimate indicates an underdispersed count. According to the
$z$ statistic, $\hat{alpha}$ is significantly different from zero
(Poisson case). Poisson is special case of Gamma-Count when $\alpha =
0$, so we can perform a likelihood ratio test to the hypothesis $H_0:
\alpha = 0$.

```{r}
# Likelihood ratio test.
chi <- 2 * (logLik(m1) - logLik(m0))
pval <- 2 * pchisq(chi, df = 1, lower.tail = FALSE)
cat("Likelihood Ratio Test\n",
    "Chisq:\t\t ", chi, "\n",
    "Pr(>Chisq):\t ", pval, "\n",
    sep = "")
```

```{r}
# Log-likelihood profile for alpha.
plot(profile(m1, which = "alpha"))
```

```{r}
cbind(c(0, coef(m0)), coef(m1))
rstd <- summary(m1)@coef[-1, 2]/summary(m0)$coeff[, 2]
plyr::each(mean, range)(rstd)
```

The estimates for the location parameters were very close. The ratio
between Gamma-Count parameters standard error and Poisson ones, on the
other hand, were `r round(mean(rstd), 3)` for all estimates, for 3 decimals of
precision. This leads to the conclusion that TODO relação linear no
parâmetro de dispersão.

```{r}
# Wald test for the interaction.
a <- c(0, attr(model.matrix(m0), "assign"))
ai <- a == max(a)
L <- t(replicate(sum(ai), rbind(coef(m1) * 0), simplify = "matrix"))
L[, ai] <- diag(sum(ai))

linearHypothesis(model = m0, # m0 is not being used here.
                 hypothesis.matrix = L,
                 vcov. = vcov(m1),
                 coef. = coef(m1))
```

```{r, eval = TRUE}
# Fitting Poisson-Tweedie model.
m2 <- mcglm(linear_pred = c(ncap ~ est * (des + I(des^2))),
            matrix_pred = list(mc_id(data = capdesfo)),
            link = "log",
            variance = "poisson_tweedie",
            power_fixed = FALSE,
            data = capdesfo,
            control_algorithm = list(verbose = FALSE,
                                     max_iter = 100,
                                     tunning = 0.5,
                                     correct = FALSE))

# Parameter estimates.
summary(m2)

plot(m2, type = "algorithm")

# Wald test for fixed effects.
anova(m2)
```

```{r}
# New data values for prediction.
pred <- with(capdesfo,
             expand.grid(est = levels(est),
                         des = seq(0, 1, length.out = 30)))

# Corresponding model matrix.
X <- model.matrix(formula(m0)[-2], data = pred)

#--------------------------------------------
# Poisson.

yp <- predict(m0, newdata = pred, se.fit = TRUE)
em <- outer(yp$se.fit,
            c(lwrP = -1, fitP = 0, uprP = 1) * qnorm(0.975),
            FUN = "*")
ci <- sweep(em, MARGIN = 1, STATS = yp$fit, FUN = "+")
ci <- m0$family$linkinv(ci)

pred <- cbind(pred, as.data.frame(ci))
str(pred)

# TODO predito pelo 3 modelos.

```

TODO: pares de estimativa e erros padrões.



<!------------------------------------------- -->
## Soybean pod and beans

The tropical soils, usually poor in potassium (K), demand potassium
fertilization when cultivated with soybean (*Glycine max* L.) to obtain
satisfactory yields. Soybean production is affected by long exposition
to water deficit. As postassium is a nutrient involved in the water
balance in plant, by hyphotesis, a good supply of potassium avoids lose
production.

The aim of this experiment was to evaluate the effects of K doses and
soil humidity levels on soybean production. The experiment was carried
out in a greenhouse, in pots with two plants, containing 5 dm^3^ of
soil. The experimental design was completely randomized block with
treatments in a 5 x 3 factorial arrangement. The K doses were 0, 30, 60,
120 and 180 mg dm^-3^ , and the soil humidity ranged from 35 to 40, 47.5
to 52.5, and 60 to 65% of the total porosity
[@Serafim2012, for more details].

Two count variables were recorded in this experiment: the total number
of pods per plot and the total number of grains per plot. The ratio,
grains/pod, can also be analysed, since the fisiological response can
change it.

There is an outlier in the dataset at position 74 that must be
removed. Potassion amount (K) will be converted to a categorical factor,
despite it is a numerical one, to prevent concerns with lack of fit,
that is not the main scope of the following analysis.

```{r}
data(soja)
str(soja)

# Removing an outlier.
soja <- soja[-74, ]
soja <- transform(soja, K = factor(K))
```

### Number of pods

<!-- Add a pod picture here -->

The pod is a dehiscent fruit of a leguminous plant such as the beans and
soybeans. The pod is the basic unit of production in soybean, so factors
that reduces or increases the number of pods have impact in crop
production.

The potassium amount (K) increased the number of pods and number of
beans in all soil water content levels (A)
(\@ref(fig:pods-beans-scatter)). For lowest soil water level, the mean
was fairly low than the other levels that perform very similar. The
pattern driven by the mean lines suggests interaction between applied
potassium amount and soil water content for both variables.

We could obtain the sample variance and sample mean for each cell
combination for checking dispersion level but it would ignore the block
effect, that can enlarges the variance.

```{r pods-beans-scatter, fig.cap = cap, echo = -(1:2)}
cap <-
"Number of pods and beans as function of potassium amount (K) for each soil water content level (%). Lines passes on the average of points. The mean response pattern is the same on the two variables."

xyplot(nvag + ngra ~ K,
       groups = umid,
       outer = TRUE,
       data = soja,
       type = c("p", "a"),
       scales = "free",
       ylab = NULL,
       xlab = expression("Applied potassium amount" ~ (mg ~ dm^{-3})),
       auto.key = list(title = "Soil water content (%)",
                       cex.title = 1,
                       columns = 3),
       strip = strip.custom(
           factor.levels = c("Number of pods",
                             "Number of beans")))
```

The following analysis with be carried out in parallel, that is, results
will be showed together in each step for the sake of comparison.

We fit Poisson (P), Gamma-Count (GC) and Poisson-Tweedie (TW) regression
models. The first two were fit by maximum likelihood and the last by
moments specification.

```{r}
#--------------------------------------------
# Poisson.

m0 <- glm(nvag ~ bloc + umid * K,
          data = soja,
          family = poisson)

#--------------------------------------------
# Gamma-Count.

m1 <- gcnt(formula(m0), data = soja)

#--------------------------------------------
# Tweedie.

m2 <- mcglm(linear_pred = c(nvag ~ bloc + umid * K),
            matrix_pred = list(mc_id(data = soja)),
            link = "log",
            variance = "poisson_tweedie",
            power_fixed = TRUE,
            data = soja,
            control_algorithm = list(verbose = FALSE,
                                     max_iter = 100,
                                     tunning = 0.5,
                                     correct = FALSE))
```

To fit Poisson and Gamma-Count, the correspond function were used in the
default setting. To fit Poisson Tweedie, we `power_fixed = TRUE` option,
since the number of pods is a close to equidispersed count variable. The
Poisson-Tweedie loses identifiability in the equidispersion zone because
the variance is $var(Y) = \mu + \phi\mu^p$, then $p$ can be any value if
$\phi$ goes to zero. We fixed $p = 1$.

```{r pods-plot-residuals, echo = FALSE, fig.cap = cap, fig.height = 7}
cap <-
    "The 4 plots for checking departures of assumptions in the GLM-Poisson regression model for number of soybean pods."
par(mfrow = c(2, 2))
plot(m0); layout(1)
```

Figure \@ref(fig:pods-plot-residuals) shows the 4 plots based on
residuals. This residuals didn't show any departure pattern. On the
contray, the axes of the qq-norm plot shows the same range, indicating a
equidispersed count variable.

The maximised log-likelihood were very close for Poisson and Gamma-Count
models. The profile log-likelihood for Gamma-Count dispersion parameter
contains 0 inside (Figure \@ref(fig:profile-alpha-pods)), so indicating
a close to Poisson case. <!-- The profile has a very simetric shape -->

```{r}
#-----------------------------------------------------------------------
# Comparing models.

# Log-likelihood.
c(P = logLik(m0), GC = logLik(m1), TW = NA)
```
```{r profile-alpha-pods, fig.cap = cap}
cap <-
    "Profile log-likelihood for the Gamma-Count dispersion parameter. The confidence interval based on profile likelihood contains 0 inside as indicated by the solid vertical line."
# Likelihhod profile for Gamma-Count dispersion parameter.
plot(profile(m1, which = "alpha"))
abline(v = 0, lty = 2)
```

The estimates and standard erros also were close on the (location)
regression parameters for all models. They differ only in the dispersion
parameter by construction.

```{r, results = "hide"}
c0 <- summary(m0)$coefficients[, 1:2]
c1 <- summary(m1)@coef[, 1:2]
c2 <- rbind(summary(m2)[[1]]$tau[, 1:2],
            summary(m2)[[1]]$Regression[, 1:2])
```
```{r}
# Parameter estimates according to each model.
c4 <- cbind("P" = rbind(NA, c0),
            "GC" = c1,
            "TW" = c2)
colnames(c4) <- substr(colnames(c4), 1, 6)
round(c4, digits = 4)
```

```{r, include = FALSE}
# V <- cov2cor(vcov(m1))
# corrplot.mixed(V,
#                lower = "number",
#                upper = "ellipse",
#                diag = "l",
#                tl.pos = "lt",
#                tl.col = "black",
#                tl.cex = 0.8,
#                col = brewer.pal(9, "Greys")
#                [-(1:3)]) dev.off()
```

Until now, all models perform very close suggesting to keep the Poisson
by parsimony. But for testing purposes, Gamma-Count and Poisson-Tweedie
got a more significant p-value for the potassium amount $\times$ soil
water content interaction. If a 5% significance is adoted, models lead
to different practical conclusions.

```{r}
# Analysis of deviance table.
anova(m0, test = "Chisq")

# Wald test for interaction.
a <- c(0, attr(model.matrix(m0), "assign"))
ai <- a == max(a)
L <- t(replicate(sum(ai), rbind(coef(m1) * 0), simplify = "matrix"))
L[, ai] <- diag(sum(ai))
linearHypothesis(model = m0, # m0 is not being used here.
                 hypothesis.matrix = L,
                 vcov. = vcov(m1),
                 coef. = coef(m1))

# Wald test for fixed effects.
anova(m2)
```

Figure \@ref(fig:segplot-pods) shows the estimated cells means with 95%
confidence intervals. All estimated means are equals along models in
each cell.  Gamma-count and Poisson-Tweedie have more shorter confidence
intervals than Poisson, because the extra flexibility enebled by fitting
a dispersion parameter.

```{r, include = FALSE}
#-----------------------------------------------------------------------
# Mean prediction.

# Cell combinations.
X <- LSmatrix(m0, effect = c("umid", "K"))
pred <- attr(X, "grid")
pred <- transform(pred,
                  K = as.integer(K),
                  umid = factor(umid))
pred <- list(P = pred, GC = pred, TW = pred)

# Poisson model prediction.
aux <- confint(glht(m0, linfct = X),
               calpha = univariate_calpha())$confint
colnames(aux)[1] <- "fit"
pred$P <- cbind(pred$P, exp(aux))

# Gamma-Count model prediction.
aux <- predict(m1, newdata = X,
               interval = "confidence",
               type = "link")
pred$GC <- cbind(pred$GC, exp(aux[, c(2, 1, 3)]))

V <- vcov(m2)
i <- grepl("^beta", rownames(V))
eta <- X %*% coef(m2, type = "beta")$Estimates
std <- sqrt(diag(as.matrix(X %*%
                           as.matrix(V[i, i]) %*%
                           t(X))))
q <- qnorm(0.975) * c(lwr = -1, fit = 0, upr = 1)
me <- outer(std, q, FUN = "*")
aux <- sweep(me, 1, eta, FUN = "+")
pred$TW <- cbind(pred$TW, exp(aux))

pred <- ldply(pred, .id = "model")
pred <- arrange(pred, umid, K, model)

key <- list(type = "o", divide = 1,
            lines = list(pch = 1:nlevels(pred$model),
                         lty = 1, col = 1),
            text = list(c("Poisson",
                          "Gamma-Count",
                          "Poisson-Tweedie")))
```
```{r segplot-pods, echo = FALSE, fig.cap = cap}
cap <- "Estimated cell means based on Poisson, Gamma-Count and Poisson-Tweedie regression models. Segments are 95% individual coverage confidence intervals."
xyplot(fit ~ K | umid,
       data = pred,
       layout = c(NA, 1),
       as.table = TRUE,
       xlim = extendrange(range(pred$K), f = 0.1),
       key = key,
       pch = pred$model,
       xlab = expression("Applied potassium amount" ~ (mg ~ dm^{-3})),
       ylab = "Number of pods per plot",
       ly = pred$lwr,
       uy = pred$upr,
       cty = "bars",
       length = 0,
       prepanel = prepanel.cbH,
       desloc = 8 * scale(as.integer(pred$model), scale = FALSE),
       panel = panel.cbH)
```

We analysed the number of soybean pods. This variable showed
equidispersion than Gamma-Count and Poisson-Tweedie perform very close
to Poisson. For testing fixed effects, on the other hand, Poisson
weren't able to detect the interaction effect under a 5% significance
level. This points out that more flexible models are powerful in
detecting effects.


### Number of grains

For the analysis of number of beans, the same steps will be carried out,
just adaptating the code when needed. The first adaptation we need make
is to overcome a numerical problem in the Gamma-Count implementation.

The Gamma-Count mass function, and also the likelihood, computes the
difference of Gamma CDF. This difference can be numerically zero by lack
of precision and this leads to a -Inf in the log-likelihood. To overcame
this, we can use an artifitial offset that can prevent those zeros. The
code below shows the effect of offset on the probabilities.

```{r}
dgcnt

y <- 0:30
lambda <- 30
alpha <- 5
off <- 1
pgamma(q = off,
       shape = y * alpha,
       rate = alpha * lambda) -
    pgamma(q = off,
           shape = (y + 1) * alpha,
           rate = alpha * lambda)

off <- off * 0.5
pgamma(q = off,
       shape = y * alpha,
       rate = alpha * lambda) -
    pgamma(q = off,
           shape = (y + 1) * alpha,
           rate = alpha * lambda)
```

The practical implication of an artificial offset is changing the size of
the unit were the counts were observed, so the estimates are multiples
of the those with offset 1. To be consistent, we will the same
artifitial offset, 10, in all models. This offset, artifitially, assumes
that the count were observed as a sum of 10 pots.

```{r}
soja$off <- 10
fivenum(with(soja, ngra/off))
```
```{r}
#--------------------------------------------
# Poisson.

m0 <- glm(ngra ~ offset(log(off)) + bloc + umid * K,
          data = soja,
          family = poisson)

#--------------------------------------------
# Gamma-Count.

m1 <- gcnt(formula(m0), data = soja)

#--------------------------------------------
# Tweedie.

m2 <- mcglm(linear_pred = c(ngra ~ bloc + umid * K),
            matrix_pred = list(mc_id(data = soja)),
            link = "log",
            offset = list(log(soja$off)),
            variance = "poisson_tweedie",
            power_fixed = FALSE,
            data = soja,
            control_algorithm = list(verbose = FALSE,
                                     max_iter = 100,
                                     tunning = 0.2,
                                     correct = FALSE))
```

To fit Poisson Tweedie for number of beans, we set `power_fixed = FALSE`
option, because the number of beans if a more dispersed variable than
number of pods. We used 0.2 for tunning to get convergence.

```{r beans-plot-residuals, echo = FALSE, fig.cap = cap, fig.height = 7}
cap <-
    "The 4 plots for checking departures of assumptions in the GLM-Poisson regression model for number of soybean pods."
par(mfrow = c(2, 2))
plot(m0); layout(1)
```

Figure \@ref(fig:beans-plot-residuals) shows the 4 plots based on
residuals. This residuals didn't show any departure pattern regarding
mispecification of the predictor (lack of fit, for example). The y axis
of the qq-norm plot has range on -3 to 4, indicating an overdispersed
count variable.

The maximised log-likelihood were different between Poisson and
Gamma-Count models. The profile log-likelihood for Gamma-Count
dispersion parameter does not contain 0 inside (Figure
\@ref(fig:profile-alpha-beans)), so indicating a overdispersed case. The
profile show a simmetric shape with almost linear or "V" shape that
indicates a quadratic profile likelihood function.

```{r}
#-----------------------------------------------------------------------
# Comparing models.

# Log-likelihood.
c(P = logLik(m0), GC = logLik(m1), TW = NA)
```
```{r profile-alpha-beans, fig.cap = cap}
cap <-
    "Profile log-likelihood for the Gamma-Count dispersion parameter. The confidence interval based on profile likelihood contains 0 inside as indicated by the solid vertical line."
# Likelihhod profile for Gamma-Count dispersion parameter.
plot(profile(m1, which = "alpha"))
```

The estimates for location parameters were the same for all three
models. The standard error for Poisson estimates were smaller than those
for Gamma-Count and Poisson-Tweedie. The ratio of standard errors
between Gamma-Count and Poisson were 1.3 (mean) and for Poisson-Tweedie
1.26 (mean).

```{r, results = "hide"}
c0 <- summary(m0)$coefficients[, 1:2]
c1 <- summary(m1)@coef[, 1:2]
c2 <- rbind(summary(m2)[[1]]$tau[, 1:2],
            summary(m2)[[1]]$Regression[, 1:2])
```
```{r}
# Parameter estimates according to each model.
c4 <- cbind("P" = rbind(NA, c0),
            "GC" = c1,
            "TW" = c2)
colnames(c4) <- substr(colnames(c4), 1, 6)
round(c4, digits = 4)

# Ratios between stardard errors.
cbind(GC = summary(c4[-1, 4]/c4[-1, 2]),
      TW = summary(c4[-1, 6]/c4[-1, 2]))
```

```{r, include = FALSE}
# V <- cov2cor(vcov(m1))
# corrplot.mixed(V,
#                lower = "number",
#                upper = "ellipse",
#                diag = "l",
#                tl.pos = "lt",
#                tl.col = "black",
#                tl.cex = 0.8,
#                col = brewer.pal(9, "Greys")
#                [-(1:3)]) dev.off()
```

The Poisson model gave the higher statistic to the rejection of the null
hypothesis than Gamma-Count and Poisson-Tweedie because it is assuming a
dispersion of 1 that is not the case. Gamma-Count and Poisson-Tweedie
perform very similar to test the interaction.

```{r}
# Analysis of deviance table.
anova(m0, test = "Chisq")

# Wald test for interaction.
a <- c(0, attr(model.matrix(m0), "assign"))
ai <- a == max(a)
L <- t(replicate(sum(ai), rbind(coef(m1) * 0), simplify = "matrix"))
L[, ai] <- diag(sum(ai))
linearHypothesis(model = m0, # m0 is not being used here.
                 hypothesis.matrix = L,
                 vcov. = vcov(m1),
                 coef. = coef(m1))

# Wald test for fixed effects.
anova(m2)
```

Figure \@ref(fig:segplot-beans) shows the estimated cells means with 95%
confidence intervals. All estimated means are equals along models in
each cell.  Gamma-count and Poisson-Tweedie have wider confidence
intervals than Poisson, because the extra variability where incorporated
on the model and have increased the estimates uncertainly.

```{r, include = FALSE}
#-----------------------------------------------------------------------
# Mean prediction.

# Because of the offset term, when can't use LSmatrix().
pred <- unique(subset(soja, select = c("umid", "K")))
X <- model.matrix(formula(m0)[-2],
                  data = cbind(off = 1, bloc = soja$bloc[1], pred))
i <- grep(x = colnames(X), pattern = "^bloc")
X[, i] <- X[, i] * 0 + 1/(length(i) + 1)
pred <- transform(pred,
                  K = as.numeric(as.character(K)),
                  umid = factor(umid))
pred <- list(P = pred, GC = pred, TW = pred)

# Poisson model prediction.
aux <- confint(glht(m0, linfct = X),
               calpha = univariate_calpha())$confint
colnames(aux)[1] <- "fit"
pred$P <- cbind(pred$P, exp(aux))

# Gamma-Count model prediction.
aux <- predict(m1, newdata = X,
               interval = "confidence",
               type = "link")
pred$GC <- cbind(pred$GC, exp(aux[, c(2, 1, 3)]))

V <- vcov(m2)
i <- grepl("^beta", rownames(V))
eta <- X %*% coef(m2, type = "beta")$Estimates
std <- sqrt(diag(as.matrix(X %*%
                           as.matrix(V[i, i]) %*%
                           t(X))))
q <- qnorm(0.975) * c(lwr = -1, fit = 0, upr = 1)
me <- outer(std, q, FUN = "*")
aux <- sweep(me, 1, eta, FUN = "+")
pred$TW <- cbind(pred$TW, exp(aux))

pred <- ldply(pred, .id = "model")
pred <- arrange(pred, umid, K, model)

key <- list(type = "o", divide = 1,
            lines = list(pch = 1:nlevels(pred$model),
                         lty = 1, col = 1),
            text = list(c("Poisson",
                          "Gamma-Count",
                          "Poisson-Tweedie")))
```
```{r segplot-beans, echo = FALSE, fig.cap = cap}
cap <- "Estimated cell means based on Poisson, Gamma-Count and Poisson-Tweedie regression models. Segments are 95% individual coverage confidence intervals."
xyplot(fit ~ K | umid,
       data = pred,
       layout = c(NA, 1),
       as.table = TRUE,
       xlim = extendrange(range(pred$K), f = 0.1),
       key = key,
       pch = pred$model,
       xlab = expression("Applied potassium amount" ~ (mg ~ dm^{-3})),
       ylab = "Number of beans per plot",
       ly = pred$lwr,
       uy = pred$upr,
       cty = "bars",
       length = 0,
       prepanel = prepanel.cbH,
       desloc = 8 * scale(as.integer(pred$model), scale = FALSE),
       panel = panel.cbH)
```

We analysed the number of soybean beans. This variable showed slight
overdispersion. Gamma-count and Poisson-Tweedie performed very similiar.

<!------------------------------------------- -->
### Number of grains per pod

Analyse the number of beans per plot is better than the total number of
beans, because the leter can be a side effect of the number of pods. We
will analyse the number of beans using the number of pods as an offset.

```{r}
#--------------------------------------------
# Poisson.

m0 <- glm(ngra ~ offset(log(nvag)) + bloc + umid * K,
          data = soja,
          family = poisson)

#--------------------------------------------
# Gamma-Count.

m1 <- gcnt(formula(m0), data = soja)

#--------------------------------------------
# Tweedie.

m2 <- mcglm(linear_pred = c(ngra ~ bloc + umid * K),
            matrix_pred = list(mc_id(data = soja)),
            link = "log",
            offset = list(log(soja$nvag)),
            variance = "poisson_tweedie",
            power_fixed = TRUE,
            data = soja,
            control_algorithm = list(verbose = FALSE,
                                     max_iter = 100,
                                     tunning = 0.5,
                                     correct = FALSE))
```

To accomplish the fitting, we set `power_fixed = TRUE` otherwise
convergence wasn't met.

```{r bp-plot-residuals, echo = FALSE, fig.cap = cap, fig.height = 7}
cap <-
    "The 4 plots for checking departures of assumptions in the GLM-Poisson regression model for number of soybean pods."
par(mfrow = c(2, 2))
plot(m0); layout(1)
```

Figure \@ref(fig:bp-plot-residuals) shows the 4 plots based on
residuals. The y axis of the qq-norm plot has
range on -1.5 to 1.5, indicating an underdispersed count variable.

The maximised log-likelihood were different between Poisson and
Gamma-Count models. The profile log-likelihood for Gamma-Count
dispersion parameter does not contain 0 inside (Figure
\@ref(fig:profile-alpha-bp)), so indicating an underdispersed
count. The profile likelihood is "V" shape that represents a quadratic
profile log-likelihood function. <!-- The profile has a very simetric shape -->

```{r}
#-----------------------------------------------------------------------
# Comparing models.

# Log-likelihood.
c(P = logLik(m0), GC = logLik(m1), TW = NA)
```
```{r profile-alpha-bp, fig.cap = cap}
cap <-
    "Profile log-likelihood for the Gamma-Count dispersion parameter. The confidence interval based on profile likelihood contains 0 inside as indicated by the solid vertical line."
# Likelihhod profile for Gamma-Count dispersion parameter.
plot(profile(m1, which = "alpha"))
```

The point estimates for location parameters were, once more, the same
for all three models. The standard error for Poisson estimates were
greater than those for Gamma-Count and Poisson-Tweedie.

```{r, results = "hide"}
c0 <- summary(m0)$coefficients[, 1:2]
c1 <- summary(m1)@coef[, 1:2]
c2 <- rbind(summary(m2)[[1]]$tau[, 1:2],
            summary(m2)[[1]]$Regression[, 1:2])
```
```{r}
# Parameter estimates according to each model.
c4 <- cbind("P" = rbind(NA, c0),
            "GC" = c1,
            "TW" = c2)
colnames(c4) <- substr(colnames(c4), 1, 6)
round(c4, digits = 4)

# Ratios between stardard errors.
cbind(GC = summary(c4[-1, 4]/c4[-1, 2]),
      TW = summary(c4[-1, 6]/c4[-1, 2]))
```


```{r, include = FALSE}
# V <- cov2cor(vcov(m1))
# corrplot.mixed(V,
#                lower = "number",
#                upper = "ellipse",
#                diag = "l",
#                tl.pos = "lt",
#                tl.col = "black",
#                tl.cex = 0.8,
#                col = brewer.pal(9, "Greys")
#                [-(1:3)]) dev.off()
```

None of the experimental factors had effect on the number of beans per
pod. Althought, Gamma-Count and Poisson-Tweedie showed more favorable
statistics to the rejection of the null hypothesis than Poisson.

```{r}
# Analysis of deviance table.
anova(m0, test = "Chisq")

# Wald test for interaction.
a <- c(0, attr(model.matrix(m0), "assign"))
ai <- a == max(a)
L <- t(replicate(sum(ai), rbind(coef(m1) * 0), simplify = "matrix"))
L[, ai] <- diag(sum(ai))
linearHypothesis(model = m0, # m0 is not being used here.
                 hypothesis.matrix = L,
                 vcov. = vcov(m1),
                 coef. = coef(m1))

# Wald test for fixed effects.
anova(m2)
```

Figure \@ref(fig:segplot-bp) shows the estimated cells means with 95%
confidence intervals. All estimated means are equals along models in
each cell.  Gamma-count and Poisson-Tweedie have more shorter confidence
intervals than Poisson.

```{r, include = FALSE}
#-----------------------------------------------------------------------
# Mean prediction.

# Because of the offset term, when can't use LSmatrix().
pred <- unique(subset(soja, select = c("umid", "K")))
X <- model.matrix(formula(m0)[-2],
                  data = cbind(nvag = 1, bloc = soja$bloc[1], pred))
i <- grep(x = colnames(X), pattern = "^bloc")
X[, i] <- X[, i] * 0 + 1/(length(i) + 1)
pred <- transform(pred,
                  K = as.numeric(as.character(K)),
                  umid = factor(umid))
pred <- list(P = pred, GC = pred, TW = pred)

# Poisson model prediction.
aux <- confint(glht(m0, linfct = X),
               calpha = univariate_calpha())$confint
colnames(aux)[1] <- "fit"
pred$P <- cbind(pred$P, exp(aux))

# Gamma-Count model prediction.
aux <- predict(m1, newdata = X,
               interval = "confidence",
               type = "link")
pred$GC <- cbind(pred$GC, exp(aux[, c(2, 1, 3)]))

V <- vcov(m2)
i <- grepl("^beta", rownames(V))
eta <- X %*% coef(m2, type = "beta")$Estimates
std <- sqrt(diag(as.matrix(X %*%
                           as.matrix(V[i, i]) %*%
                           t(X))))
q <- qnorm(0.975) * c(lwr = -1, fit = 0, upr = 1)
me <- outer(std, q, FUN = "*")
aux <- sweep(me, 1, eta, FUN = "+")
pred$TW <- cbind(pred$TW, exp(aux))

pred <- ldply(pred, .id = "model")
pred <- arrange(pred, umid, K, model)

key <- list(type = "o", divide = 1,
            lines = list(pch = 1:nlevels(pred$model),
                         lty = 1, col = 1),
            text = list(c("Poisson",
                          "Gamma-Count",
                          "Poisson-Tweedie")))
```
```{r segplot-bp, echo = FALSE, fig.cap = cap}
cap <- "Estimated cell means based on Poisson, Gamma-Count and Poisson-Tweedie regression models. Segments are 95% individual coverage confidence intervals."
xyplot(fit ~ K | umid,
       data = pred,
       layout = c(NA, 1),
       as.table = TRUE,
       xlim = extendrange(range(pred$K), f = 0.1),
       key = key,
       pch = pred$model,
       xlab = expression("Applied potassium amount" ~ (mg ~ dm^{-3})),
       ylab = "Number of beans per pod",
       ly = pred$lwr,
       uy = pred$upr,
       cty = "bars",
       length = 0,
       prepanel = prepanel.cbH,
       desloc = 8 * scale(as.integer(pred$model), scale = FALSE),
       panel = panel.cbH)
```

We analysed the number of beans por pod in a experiment with
soybeans. This variable showed underdispersion so Gamma-Count and
Poisson-Tweedie perform better than Poisson. <!-- TODO complementar -->


## Number of vehicle claims
