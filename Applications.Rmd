# Applications

In this chapter, we will bring some applications based on real data
sets to show how use R packages to analyse count data.

## Cotton Bolls

Cotton production can be drastically reduced by attack of defoliating
insects. Depending on the growth stage, the plant can recover from the
caused damage and keeps production not affected or can have the
production reduced by low intensity defoliation.

A greenhouse experiment with cotton plants (*Gossypium hirsutum*) was
done under a completely randomized design with five replicates to assess
the effects of five defoliation levels (0%, 25%, 50%,75% and 100%) on
the observed number of bolls produced by plants at five growth stages:
vegetative, flower-bud, blossom, fig and cotton boll. The experimental
unity was a pot with two plants [@Silva2012a, for more]. The number of
cotton bolls was recorded at the hasvest of the experiment.

```{r, message = FALSE}
library(lattice)
library(latticeExtra)
library(gridExtra)
library(plyr)
library(car)
library(corrplot)
library(doBy)
library(multcomp)
library(mcglm)
library(MRDCr)
ls("package:MRDCr")
```
```{r, eval = FALSE}
# Documentation in Portuguese.
help(capdesfo, help_type = "html")
```
```{r}
str(capdesfo)
levels(capdesfo$est) <- c("vegetative",
                          "flower-bud",
                          "blossom",
                          "fig",
                          "cotton boll")
xtabs(~est + des, data = capdesfo)
```

Figure \@ref(fig:bools-mean-var) (top) shows the beeswarm plot of number
of cotton bolls recorded for each combination of defoliation level and
growth stage. All the points in the sample means and variances
dispersion diagram (bottom) are below the identity line, clearly
suggesting data with underdispersion.

```{r bools-mean-var, fig.cap = cap, echo = FALSE, fig.height = 10}
cap <- "(top) Number of bolls produced for each artificial defoliation level and each growth stage. (bottom) Sample variance against the sample mean of the five replicates for each combination of defoliation level and growth stage."

xy1 <- xyplot(ncap ~ des | est,
              data = capdesfo,
              layout = c(NA, 2),
              type = c("p", "smooth"),
              xlab = "Artifitial defoliation levels",
              ylab = "Bolls produced",
              as.table = TRUE,
              grid = TRUE,
              xlim = extendrange(c(0:1), f = 0.15),
              panel = panel.beeswarm,
              spread = 0.05)

mv <- aggregate(ncap ~ est + des, data = capdesfo,
                FUN = function(x) c(mean = mean(x), var = var(x)))
xlim <- ylim <- extendrange(c(mv$ncap), f = 0.05)

xy2 <- xyplot(ncap[, "var"] ~ ncap[, "mean"],
              data = mv,
              xlim = xlim,
              ylim = ylim,
              ylab = "Sample variance",
              xlab = "Sample mean",
              panel = function(x, y) {
                  panel.xyplot(x, y, type = c("p", "r"), grid = TRUE)
                  panel.abline(a = 0, b = 1, lty = 2)
              })

grid.arrange(xy1, xy2, ncol = 1)
```

The exploratory data analysis, although simple, was able to detect
departures from the Poisson equidispersion assumption. So, we have in
advance few conditions met for the use of GLM Poisson as a regression
model to analyse this experiment.

Poisson, as being a process derived from the memoryless waiting times
Exponential distribuition, implies that each boll is an independent
event in the artificial subjacent domain, that can be thought was the
natural resource domain that the plant has to allocate bolls. Its is
easy to assume, based on plant fisiology, that the probability of a boll
decreases with the number of previous bolls because the plant's resource
to produce bolls is limited and it is a non memoryless process
equivalent.

<!--

We are going to convert artifitial defoliation (`desf`) to categorial,
despite is a numeric factor, to avoid lack of fit concerns that are out
of scope here.

-->

<!--

To access the effects of the experimental factors, nested models in
terms of linear predictors were fitted, as described by the following
structures for the log-link function $g()$.

  1. $g(\mu) = \beta_0$ (null model);
  2. $g(\mu) = \beta_0 + \beta_1 \text{def}$ (1st order effect of
     defoliation);
  3. $g(\mu) = \beta_0 + \beta_1 \text{def} + \beta_2 \text{def}^2$
     (2nd order effect of defoliation);
  4. $g(\mu) = \beta_0 + \beta_{1j} \text{def} + \beta_2
     \text{def}^2$ (1st order defoliation effect for each growth stage);
  5. $g(\mu) = \beta_0 + \beta_{1j} \text{def}
     + \beta_{2j} \text{def}^2$ (2nd order effect defoliation for each
     growth stage).

-->

Based on the exploratory data analysis, a predictor with 2nd order
effect of defoliation for each growth stage should be enough to model
the number of bolls mean in a regression model. The analysis and
assessment of the effects of the experimental factors are based on the
Poisson, Gamma-count and Poisson Tweedie models.

```{r}
m0 <- glm(ncap ~ est * (des + I(des^2)),
          data = capdesfo,
          family = poisson)

summary(m0)
logLik(m0)
```
```{r, include = FALSE}
rdev <- round(deviance(m0), 2)
rdf <- df.residual(m0)
rat <- rdev/rdf
```

We fit the GLM Poisson regression model using the stardard `glm()`
function in R. The fitted model summary shows the estimated parameters
for the second order effect of defoliation crossed with growth stages
levels. The residual deviance was `r rdev` based on `r rdf` degrees of
freedoom. The ratio $`r rdev`/`r rdf` = `r rat`$ is a strong evidence
against Poisson equidispersion assumption that uses a dispersion
parameter equals 1.

```{r}
anova(m0, test = "Chisq")
```

The analysis of deviance table did not stated effect of any
interactions, neither second order effect of defiliation. Although, all
these effects are noticeable in Figure \@ref(bools-mean-var).

```{r bolls-plot-residuals, echo = FALSE, fig.cap = cap, fig.height = 7}
cap <-
    "The 4 plots for checking departures of assumptions in the GLM-Poisson regression model for the number of cotton bolls."
par(mfrow = c(2, 2))
plot(m0); layout(1)
```

Figure \@ref(bolls-plot-residuals) displays the four residual plots for
the fitted model. Based on these plots, there is no concern about
mispecifications regarding to the model predictor or influential
observations.  The only remarkable aspect is about the range of the
stardartized deviance residuals quite distant from the expected -3 to 3
from the normal distribution. Once more, these is another measure
indicating a underdispersed count data.

The `gcnt()` is a function defined in the `MRDCr` package [@mrdcr-pkg]
to fit the Gamma-Count regression model. This function fits a
GML-Poisson to use the estimates as initial values to optimize
Gamma-Count likelihood using `optim()` through `bblme` package
[@bblme-pkg].

```{r}
m1 <- gcnt(ncap ~ est * (des + I(des^2)),
           data = capdesfo)
summary(m1)
```

During the optimization process for this dataset, `optim()` has found
`NaN` when evaluating the likelihood. This occurs due little numerical
precision to calculate the difference of Gamma CDFs on tails or for
extreme values, resulting in numerical zeros and corresponding `-Inf`
log-likelihood. This is a numerical problem that can narrow, or make
things difficult, the use of Gamma-Count regression model.

The dispersion parameter is the first position in the parameter
vector. The optimization was carried out on the log scale to avoid
problems regarding to bounded parameter spaces.  As the dispersion
parameter is in fact interpreted as a precision coefficient, the
positive estimate indicates an underdispersed count. According to the
$z$ statistic, $\hat{alpha}$ is significantly different from zero
(Poisson case). Poisson is special case of Gamma-Count when $\alpha =
0$, so we can perform a likelihood ratio test to the hypothesis $H_0:
\alpha = 0$.

```{r}
# Likelihood ratio test.
chi <- 2 * (logLik(m1) - logLik(m0))
pval <- 2 * pchisq(chi, df = 1, lower.tail = FALSE)
cat("Likelihood Ratio Test\n",
    "Chisq:\t\t ", chi, "\n",
    "Pr(>Chisq):\t ", pval, "\n",
    sep = "")
```

```{r}
# Log-likelihood profile for alpha.
plot(profile(m1, which = "alpha"))
```

```{r}
cbind(c(0, coef(m0)), coef(m1))
rstd <- summary(m1)@coef[-1, 2]/summary(m0)$coeff[, 2]
plyr::each(mean, range)(rstd)
```

The estimates for the location parameters were very close. The ratio
between Gamma-Count parameters standard error and Poisson ones, on the
other hand, were `r round(mean(rstd), 3)` for all estimates, for 3 decimals of
precision. This leads to the conclusion that TODO relação linear no
parâmetro de dispersão.

```{r}
# Wald test for the interaction.
a <- c(0, attr(model.matrix(m0), "assign"))
ai <- a == max(a)
L <- t(replicate(sum(ai), rbind(coef(m1) * 0), simplify = "matrix"))
L[, ai] <- diag(sum(ai))

linearHypothesis(model = m0, # m0 is not being used here.
                 hypothesis.matrix = L,
                 vcov. = vcov(m1),
                 coef. = coef(m1))
```

```{r, eval = TRUE}
# Fitting Poisson-Tweedie model.
m2 <- mcglm(linear_pred = c(ncap ~ est * (des + I(des^2))),
            matrix_pred = list(mc_id(data = capdesfo)),
            link = "log",
            variance = "poisson_tweedie",
            power_fixed = FALSE,
            data = capdesfo,
            control_algorithm = list(verbose = FALSE,
                                     max_iter = 100,
                                     tunning = 0.5,
                                     correct = FALSE))

# Parameter estimates.
summary(m2)

# Wald test for fixed effects.
anova(m2)
```

```{r}
# New data values for prediction.
pred <- with(capdesfo,
             expand.grid(est = levels(est),
                         des = seq(0, 1, length.out = 30)))

# Corresponding model matrix.
X <- model.matrix(formula(m0)[-2], data = pred)
pred <- list(P = pred, GC = pred, TW = pred)

# Poisson model prediction.
aux <- confint(glht(m0, linfct = X),
               calpha = univariate_calpha())$confint
colnames(aux)[1] <- "fit"
pred$P <- cbind(pred$P, exp(aux))

# Gamma-Count model prediction.
# aux <- predict(m1, newdata = X,
#                interval = "confidence",
#                type = "link")
# pred$GC <- cbind(pred$GC, exp(aux[, c(2, 1, 3)]))
aux <- predict(m1, newdata = X,
               interval = "confidence",
               type = "response")
pred$GC <- cbind(pred$GC, aux[, c(2, 1, 3)])

V <- vcov(m2)
i <- grepl("^beta", rownames(V))
eta <- X %*% coef(m2, type = "beta")$Estimates
std <- sqrt(diag(as.matrix(X %*%
                           as.matrix(V[i, i]) %*%
                           t(X))))
q <- qnorm(0.975) * c(lwr = -1, fit = 0, upr = 1)
me <- outer(std, q, FUN = "*")
aux <- sweep(me, 1, eta, FUN = "+")
pred$TW <- cbind(pred$TW, exp(aux))

pred <- ldply(pred, .id = "model")
pred <- arrange(pred, est, des, model)

key <- list(type = "o", divide = 1,
            lines = list(pch = 1:nlevels(pred$model),
                         lty = 1, col = 1),
            text = list(c("Poisson",
                          "Gamma-Count",
                          "Poisson-Tweedie")))

key <- list(lines = list(lty = 1),
            text = list(c("Poisson",
                          "Gamma-Count",
                          "Poisson-Tweedie")))
key$lines$col <-
    trellis.par.get("superpose.line")$col[1:nlevels(pred$model)]
```
```{r bolls-bands, echo = FALSE, fig.cap = cap, fig.height = 5.5}
cap <- "Fitted curves based on Poisson, Gamma-Count and Poisson-Tweedie regression models. Envelops are 95% coverage confidence bands."
update(xy1,
       type = "p",
       key = key) +
    as.layer(xyplot(fit ~ des | est,
                    groups = model,
                    data = pred,
                    # layout = c(NA, 1),
                    as.table = TRUE,
                    xlim = extendrange(range(pred$des), f = 0.1),
                    key = key,
                    type = "l",
                    xlab = "Artifitial defoliation",
                    ylab = "Number of bolls per plot",
                    ly = pred$lwr,
                    uy = pred$upr,
                    cty = "bands",
                    alpha = 0.35,
                    prepanel = prepanel.cbH,
                    panel.groups = panel.cbH,
                    panel = panel.superpose), under = TRUE)
```

```{r, results = "hide"}
c0 <- summary(m0)$coefficients[, 1:2]
c1 <- summary(m1)@coef[, 1:2]
c2 <- rbind(summary(m2)[[1]]$tau[, 1:2],
            summary(m2)[[1]]$Regression[, 1:2])
```
```{r}
# Parameter estimates according to each model.
c4 <- cbind("P" = rbind(NA, c0),
            "GC" = c1,
            "TW" = c2)
colnames(c4) <- substr(colnames(c4), 1, 6)
round(c4, digits = 4)
```

<!------------------------------------------- -->
## Soybean pod and beans

The tropical soils, usually poor in potassium (K), demand potassium
fertilization when cultivated with soybean (*Glycine max* L.) to obtain
satisfactory yields. Soybean production is affected by long exposition
to water deficit. As postassium is a nutrient involved in the water
balance in plant, by hyphotesis, a good supply of potassium avoids lose
production.

The aim of this experiment was to evaluate the effects of K doses and
soil humidity levels on soybean production. The experiment was carried
out in a greenhouse, in pots with two plants, containing 5 dm^3^ of
soil. The experimental design was completely randomized block with
treatments in a 5 x 3 factorial arrangement. The K doses were 0, 30, 60,
120 and 180 mg dm^-3^ , and the soil humidity ranged from 35 to 40, 47.5
to 52.5, and 60 to 65% of the total porosity
[@Serafim2012, for more details].

Two count variables were recorded in this experiment: the total number
of pods per plot and the total number of grains per plot. The ratio,
grains/pod, can also be analysed, since the fisiological response can
change it.

There is an outlier in the dataset at position 74 that must be
removed. Potassion amount (K) will be converted to a categorical factor,
despite it is a numerical one, to prevent concerns with lack of fit,
that is not the main scope of the following analysis.

```{r}
data(soja)
str(soja)

# Removing an outlier.
soja <- soja[-74, ]
soja <- transform(soja, K = factor(K))
```

### Number of pods

<!-- Add a pod picture here -->

The pod is a dehiscent fruit of a leguminous plant such as the beans and
soybeans. The pod is the basic unit of production in soybean, so factors
that reduces or increases the number of pods have impact in crop
production.

The potassium amount (K) increased the number of pods and number of
beans in all soil water content levels (A)
(\@ref(fig:pods-beans-scatter)). For lowest soil water level, the mean
was fairly low than the other levels that perform very similar. The
pattern driven by the mean lines suggests interaction between applied
potassium amount and soil water content for both variables.

We could obtain the sample variance and sample mean for each cell
combination for checking dispersion level but it would ignore the block
effect, that can enlarges the variance.

```{r pods-beans-scatter, fig.cap = cap, echo = -(1:2)}
cap <-
"Number of pods and beans as function of potassium amount (K) for each soil water content level (%). Lines passes on the average of points. The mean response pattern is the same on the two variables."

xyplot(nvag + ngra ~ K,
       groups = umid,
       outer = TRUE,
       data = soja,
       type = c("p", "a"),
       scales = "free",
       ylab = NULL,
       xlab = expression("Applied potassium amount" ~ (mg ~ dm^{-3})),
       auto.key = list(title = "Soil water content (%)",
                       cex.title = 1,
                       columns = 3),
       strip = strip.custom(
           factor.levels = c("Number of pods",
                             "Number of beans")))
```

The following analysis with be carried out in parallel, that is, results
will be showed together in each step for the sake of comparison.

We fit Poisson (P), Gamma-Count (GC) and Poisson-Tweedie (TW) regression
models. The first two were fit by maximum likelihood and the last by
moments specification.

```{r}
#--------------------------------------------
# Poisson.

m0 <- glm(nvag ~ bloc + umid * K,
          data = soja,
          family = poisson)

#--------------------------------------------
# Gamma-Count.

m1 <- gcnt(formula(m0), data = soja)

#--------------------------------------------
# Tweedie.

m2 <- mcglm(linear_pred = c(nvag ~ bloc + umid * K),
            matrix_pred = list(mc_id(data = soja)),
            link = "log",
            variance = "poisson_tweedie",
            power_fixed = TRUE,
            data = soja,
            control_algorithm = list(verbose = FALSE,
                                     max_iter = 100,
                                     tunning = 0.5,
                                     correct = FALSE))
```

To fit Poisson and Gamma-Count, the correspond function were used in the
default setting. To fit Poisson Tweedie, we `power_fixed = TRUE` option,
since the number of pods is a close to equidispersed count variable. The
Poisson-Tweedie loses identifiability in the equidispersion zone because
the variance is $var(Y) = \mu + \phi\mu^p$, then $p$ can be any value if
$\phi$ goes to zero. We fixed $p = 1$.

```{r pods-plot-residuals, echo = FALSE, fig.cap = cap, fig.height = 7}
cap <-
    "The 4 plots for checking departures of assumptions in the GLM-Poisson regression model for number of soybean pods."
par(mfrow = c(2, 2))
plot(m0); layout(1)
```

Figure \@ref(fig:pods-plot-residuals) shows the 4 plots based on
residuals. This residuals didn't show any departure pattern. On the
contray, the axes of the qq-norm plot shows the same range, indicating a
equidispersed count variable.

The maximised log-likelihood were very close for Poisson and Gamma-Count
models. The profile log-likelihood for Gamma-Count dispersion parameter
contains 0 inside (Figure \@ref(fig:profile-alpha-pods)), so indicating
a close to Poisson case. <!-- The profile has a very simetric shape -->

```{r}
#-----------------------------------------------------------------------
# Comparing models.

# Log-likelihood.
c(P = logLik(m0), GC = logLik(m1), TW = NA)
```
```{r profile-alpha-pods, fig.cap = cap}
cap <-
    "Profile log-likelihood for the Gamma-Count dispersion parameter. The confidence interval based on profile likelihood contains 0 inside as indicated by the solid vertical line."
# Likelihhod profile for Gamma-Count dispersion parameter.
plot(profile(m1, which = "alpha"))
abline(v = 0, lty = 2)
```

The estimates and standard erros also were close on the (location)
regression parameters for all models. They differ only in the dispersion
parameter by construction.

```{r, results = "hide"}
c0 <- summary(m0)$coefficients[, 1:2]
c1 <- summary(m1)@coef[, 1:2]
c2 <- rbind(summary(m2)[[1]]$tau[, 1:2],
            summary(m2)[[1]]$Regression[, 1:2])
```
```{r}
# Parameter estimates according to each model.
c4 <- cbind("P" = rbind(NA, c0),
            "GC" = c1,
            "TW" = c2)
colnames(c4) <- substr(colnames(c4), 1, 6)
round(c4, digits = 4)
```

```{r, include = FALSE}
# V <- cov2cor(vcov(m1))
# corrplot.mixed(V,
#                lower = "number",
#                upper = "ellipse",
#                diag = "l",
#                tl.pos = "lt",
#                tl.col = "black",
#                tl.cex = 0.8,
#                col = brewer.pal(9, "Greys")
#                [-(1:3)]) dev.off()
```

Until now, all models perform very close suggesting to keep the Poisson
by parsimony. But for testing purposes, Gamma-Count and Poisson-Tweedie
got a more significant p-value for the potassium amount $\times$ soil
water content interaction. If a 5% significance is adoted, models lead
to different practical conclusions.

```{r}
# Analysis of deviance table.
anova(m0, test = "Chisq")

# Wald test for interaction.
a <- c(0, attr(model.matrix(m0), "assign"))
ai <- a == max(a)
L <- t(replicate(sum(ai), rbind(coef(m1) * 0), simplify = "matrix"))
L[, ai] <- diag(sum(ai))
linearHypothesis(model = m0, # m0 is not being used here.
                 hypothesis.matrix = L,
                 vcov. = vcov(m1),
                 coef. = coef(m1))

# Wald test for fixed effects.
anova(m2)
```

Figure \@ref(fig:segplot-pods) shows the estimated cells means with 95%
confidence intervals. All estimated means are equals along models in
each cell.  Gamma-count and Poisson-Tweedie have more shorter confidence
intervals than Poisson, because the extra flexibility enebled by fitting
a dispersion parameter.

```{r, include = FALSE}
#-----------------------------------------------------------------------
# Mean prediction.

# Cell combinations.
X <- LSmatrix(m0, effect = c("umid", "K"))
pred <- attr(X, "grid")
pred <- transform(pred,
                  K = as.integer(K),
                  umid = factor(umid))
pred <- list(P = pred, GC = pred, TW = pred)

# Poisson model prediction.
aux <- confint(glht(m0, linfct = X),
               calpha = univariate_calpha())$confint
colnames(aux)[1] <- "fit"
pred$P <- cbind(pred$P, exp(aux))

# Gamma-Count model prediction.
aux <- predict(m1, newdata = X,
               interval = "confidence",
               type = "link")
pred$GC <- cbind(pred$GC, exp(aux[, c(2, 1, 3)]))

V <- vcov(m2)
i <- grepl("^beta", rownames(V))
eta <- X %*% coef(m2, type = "beta")$Estimates
std <- sqrt(diag(as.matrix(X %*%
                           as.matrix(V[i, i]) %*%
                           t(X))))
q <- qnorm(0.975) * c(lwr = -1, fit = 0, upr = 1)
me <- outer(std, q, FUN = "*")
aux <- sweep(me, 1, eta, FUN = "+")
pred$TW <- cbind(pred$TW, exp(aux))

pred <- ldply(pred, .id = "model")
pred <- arrange(pred, umid, K, model)

key <- list(type = "o", divide = 1,
            lines = list(pch = 1:nlevels(pred$model),
                         lty = 1, col = 1),
            text = list(c("Poisson",
                          "Gamma-Count",
                          "Poisson-Tweedie")))
```
```{r segplot-pods, echo = FALSE, fig.cap = cap}
cap <- "Estimated cell means based on Poisson, Gamma-Count and Poisson-Tweedie regression models. Segments are 95% individual coverage confidence intervals."
xyplot(fit ~ K | umid,
       data = pred,
       layout = c(NA, 1),
       as.table = TRUE,
       xlim = extendrange(range(pred$K), f = 0.1),
       key = key,
       pch = pred$model,
       xlab = expression("Applied potassium amount" ~ (mg ~ dm^{-3})),
       ylab = "Number of pods per plot",
       ly = pred$lwr,
       uy = pred$upr,
       cty = "bars",
       length = 0,
       prepanel = prepanel.cbH,
       desloc = 8 * scale(as.integer(pred$model), scale = FALSE),
       panel = panel.cbH)
```

We analysed the number of soybean pods. This variable showed
equidispersion than Gamma-Count and Poisson-Tweedie perform very close
to Poisson. For testing fixed effects, on the other hand, Poisson
weren't able to detect the interaction effect under a 5% significance
level. This points out that more flexible models are powerful in
detecting effects.


### Number of grains

For the analysis of number of beans, the same steps will be carried out,
just adaptating the code when needed. The first adaptation we need make
is to overcome a numerical problem in the Gamma-Count implementation.

The Gamma-Count mass function, and also the likelihood, computes the
difference of Gamma CDF. This difference can be numerically zero by lack
of precision and this leads to a -Inf in the log-likelihood. To overcame
this, we can use an artifitial offset that can prevent those zeros. The
code below shows the effect of offset on the probabilities.

```{r}
dgcnt

y <- 0:30
lambda <- 30
alpha <- 5
off <- 1
pgamma(q = off,
       shape = y * alpha,
       rate = alpha * lambda) -
    pgamma(q = off,
           shape = (y + 1) * alpha,
           rate = alpha * lambda)

off <- off * 0.5
pgamma(q = off,
       shape = y * alpha,
       rate = alpha * lambda) -
    pgamma(q = off,
           shape = (y + 1) * alpha,
           rate = alpha * lambda)
```

The practical implication of an artificial offset is changing the size of
the unit were the counts were observed, so the estimates are multiples
of the those with offset 1. To be consistent, we will the same
artifitial offset, 10, in all models. This offset, artifitially, assumes
that the count were observed as a sum of 10 pots.

```{r}
soja$off <- 10
fivenum(with(soja, ngra/off))
```
```{r}
#--------------------------------------------
# Poisson.

m0 <- glm(ngra ~ offset(log(off)) + bloc + umid * K,
          data = soja,
          family = poisson)

#--------------------------------------------
# Gamma-Count.

m1 <- gcnt(formula(m0), data = soja)

#--------------------------------------------
# Tweedie.

m2 <- mcglm(linear_pred = c(ngra ~ bloc + umid * K),
            matrix_pred = list(mc_id(data = soja)),
            link = "log",
            offset = list(log(soja$off)),
            variance = "poisson_tweedie",
            power_fixed = FALSE,
            data = soja,
            control_algorithm = list(verbose = FALSE,
                                     max_iter = 100,
                                     tunning = 0.2,
                                     correct = FALSE))
```

To fit Poisson Tweedie for number of beans, we set `power_fixed = FALSE`
option, because the number of beans if a more dispersed variable than
number of pods. We used 0.2 for tunning to get convergence.

```{r beans-plot-residuals, echo = FALSE, fig.cap = cap, fig.height = 7}
cap <-
    "The 4 plots for checking departures of assumptions in the GLM-Poisson regression model for number of soybean pods."
par(mfrow = c(2, 2))
plot(m0); layout(1)
```

Figure \@ref(fig:beans-plot-residuals) shows the 4 plots based on
residuals. This residuals didn't show any departure pattern regarding
mispecification of the predictor (lack of fit, for example). The y axis
of the qq-norm plot has range on -3 to 4, indicating an overdispersed
count variable.

The maximised log-likelihood were different between Poisson and
Gamma-Count models. The profile log-likelihood for Gamma-Count
dispersion parameter does not contain 0 inside (Figure
\@ref(fig:profile-alpha-beans)), so indicating a overdispersed case. The
profile show a simmetric shape with almost linear or "V" shape that
indicates a quadratic profile likelihood function.

```{r}
#-----------------------------------------------------------------------
# Comparing models.

# Log-likelihood.
c(P = logLik(m0), GC = logLik(m1), TW = NA)
```
```{r profile-alpha-beans, fig.cap = cap}
cap <-
    "Profile log-likelihood for the Gamma-Count dispersion parameter. The confidence interval based on profile likelihood contains 0 inside as indicated by the solid vertical line."
# Likelihhod profile for Gamma-Count dispersion parameter.
plot(profile(m1, which = "alpha"))
```

The estimates for location parameters were the same for all three
models. The standard error for Poisson estimates were smaller than those
for Gamma-Count and Poisson-Tweedie. The ratio of standard errors
between Gamma-Count and Poisson were 1.3 (mean) and for Poisson-Tweedie
1.26 (mean).

```{r, results = "hide"}
c0 <- summary(m0)$coefficients[, 1:2]
c1 <- summary(m1)@coef[, 1:2]
c2 <- rbind(summary(m2)[[1]]$tau[, 1:2],
            summary(m2)[[1]]$Regression[, 1:2])
```
```{r}
# Parameter estimates according to each model.
c4 <- cbind("P" = rbind(NA, c0),
            "GC" = c1,
            "TW" = c2)
colnames(c4) <- substr(colnames(c4), 1, 6)
round(c4, digits = 4)

# Ratios between stardard errors.
cbind(GC = summary(c4[-1, 4]/c4[-1, 2]),
      TW = summary(c4[-1, 6]/c4[-1, 2]))
```

```{r, include = FALSE}
# V <- cov2cor(vcov(m1))
# corrplot.mixed(V,
#                lower = "number",
#                upper = "ellipse",
#                diag = "l",
#                tl.pos = "lt",
#                tl.col = "black",
#                tl.cex = 0.8,
#                col = brewer.pal(9, "Greys")
#                [-(1:3)]) dev.off()
```

The Poisson model gave the higher statistic to the rejection of the null
hypothesis than Gamma-Count and Poisson-Tweedie because it is assuming a
dispersion of 1 that is not the case. Gamma-Count and Poisson-Tweedie
perform very similar to test the interaction.

```{r}
# Analysis of deviance table.
anova(m0, test = "Chisq")

# Wald test for interaction.
a <- c(0, attr(model.matrix(m0), "assign"))
ai <- a == max(a)
L <- t(replicate(sum(ai), rbind(coef(m1) * 0), simplify = "matrix"))
L[, ai] <- diag(sum(ai))
linearHypothesis(model = m0, # m0 is not being used here.
                 hypothesis.matrix = L,
                 vcov. = vcov(m1),
                 coef. = coef(m1))

# Wald test for fixed effects.
anova(m2)
```

Figure \@ref(fig:segplot-beans) shows the estimated cells means with 95%
confidence intervals. All estimated means are equals along models in
each cell.  Gamma-count and Poisson-Tweedie have wider confidence
intervals than Poisson, because the extra variability where incorporated
on the model and have increased the estimates uncertainly.

```{r, include = FALSE}
#-----------------------------------------------------------------------
# Mean prediction.

# Because of the offset term, when can't use LSmatrix().
pred <- unique(subset(soja, select = c("umid", "K")))
X <- model.matrix(formula(m0)[-2],
                  data = cbind(off = 1, bloc = soja$bloc[1], pred))
i <- grep(x = colnames(X), pattern = "^bloc")
X[, i] <- X[, i] * 0 + 1/(length(i) + 1)
pred <- transform(pred,
                  K = as.numeric(as.character(K)),
                  umid = factor(umid))
pred <- list(P = pred, GC = pred, TW = pred)

# Poisson model prediction.
aux <- confint(glht(m0, linfct = X),
               calpha = univariate_calpha())$confint
colnames(aux)[1] <- "fit"
pred$P <- cbind(pred$P, exp(aux))

# Gamma-Count model prediction.
aux <- predict(m1, newdata = X,
               interval = "confidence",
               type = "link")
pred$GC <- cbind(pred$GC, exp(aux[, c(2, 1, 3)]))

V <- vcov(m2)
i <- grepl("^beta", rownames(V))
eta <- X %*% coef(m2, type = "beta")$Estimates
std <- sqrt(diag(as.matrix(X %*%
                           as.matrix(V[i, i]) %*%
                           t(X))))
q <- qnorm(0.975) * c(lwr = -1, fit = 0, upr = 1)
me <- outer(std, q, FUN = "*")
aux <- sweep(me, 1, eta, FUN = "+")
pred$TW <- cbind(pred$TW, exp(aux))

pred <- ldply(pred, .id = "model")
pred <- arrange(pred, umid, K, model)

key <- list(type = "o", divide = 1,
            lines = list(pch = 1:nlevels(pred$model),
                         lty = 1, col = 1),
            text = list(c("Poisson",
                          "Gamma-Count",
                          "Poisson-Tweedie")))
```
```{r segplot-beans, echo = FALSE, fig.cap = cap}
cap <- "Estimated cell means based on Poisson, Gamma-Count and Poisson-Tweedie regression models. Segments are 95% individual coverage confidence intervals."
xyplot(fit ~ K | umid,
       data = pred,
       layout = c(NA, 1),
       as.table = TRUE,
       xlim = extendrange(range(pred$K), f = 0.1),
       key = key,
       pch = pred$model,
       xlab = expression("Applied potassium amount" ~ (mg ~ dm^{-3})),
       ylab = "Number of beans per plot",
       ly = pred$lwr,
       uy = pred$upr,
       cty = "bars",
       length = 0,
       prepanel = prepanel.cbH,
       desloc = 8 * scale(as.integer(pred$model), scale = FALSE),
       panel = panel.cbH)
```

We analysed the number of soybean beans. This variable showed slight
overdispersion. Gamma-count and Poisson-Tweedie performed very similiar.

<!------------------------------------------- -->
### Number of grains per pod

Analyse the number of beans per plot is better than the total number of
beans, because the leter can be a side effect of the number of pods. We
will analyse the number of beans using the number of pods as an offset.

```{r}
#--------------------------------------------
# Poisson.

m0 <- glm(ngra ~ offset(log(nvag)) + bloc + umid * K,
          data = soja,
          family = poisson)

#--------------------------------------------
# Gamma-Count.

m1 <- gcnt(formula(m0), data = soja)

#--------------------------------------------
# Tweedie.

m2 <- mcglm(linear_pred = c(ngra ~ bloc + umid * K),
            matrix_pred = list(mc_id(data = soja)),
            link = "log",
            offset = list(log(soja$nvag)),
            variance = "poisson_tweedie",
            power_fixed = TRUE,
            data = soja,
            control_algorithm = list(verbose = FALSE,
                                     max_iter = 100,
                                     tunning = 0.5,
                                     correct = FALSE))
```

To accomplish the fitting, we set `power_fixed = TRUE` otherwise
convergence wasn't met.

```{r bp-plot-residuals, echo = FALSE, fig.cap = cap, fig.height = 7}
cap <-
    "The 4 plots for checking departures of assumptions in the GLM-Poisson regression model for number of soybean pods."
par(mfrow = c(2, 2))
plot(m0); layout(1)
```

Figure \@ref(fig:bp-plot-residuals) shows the 4 plots based on
residuals. The y axis of the qq-norm plot has
range on -1.5 to 1.5, indicating an underdispersed count variable.

The maximised log-likelihood were different between Poisson and
Gamma-Count models. The profile log-likelihood for Gamma-Count
dispersion parameter does not contain 0 inside (Figure
\@ref(fig:profile-alpha-bp)), so indicating an underdispersed
count. The profile likelihood is "V" shape that represents a quadratic
profile log-likelihood function. <!-- The profile has a very simetric shape -->

```{r}
#-----------------------------------------------------------------------
# Comparing models.

# Log-likelihood.
c(P = logLik(m0), GC = logLik(m1), TW = NA)
```
```{r profile-alpha-bp, fig.cap = cap}
cap <-
    "Profile log-likelihood for the Gamma-Count dispersion parameter. The confidence interval based on profile likelihood contains 0 inside as indicated by the solid vertical line."
# Likelihhod profile for Gamma-Count dispersion parameter.
plot(profile(m1, which = "alpha"))
```

The point estimates for location parameters were, once more, the same
for all three models. The standard error for Poisson estimates were
greater than those for Gamma-Count and Poisson-Tweedie.

```{r, results = "hide"}
c0 <- summary(m0)$coefficients[, 1:2]
c1 <- summary(m1)@coef[, 1:2]
c2 <- rbind(summary(m2)[[1]]$tau[, 1:2],
            summary(m2)[[1]]$Regression[, 1:2])
```
```{r}
# Parameter estimates according to each model.
c4 <- cbind("P" = rbind(NA, c0),
            "GC" = c1,
            "TW" = c2)
colnames(c4) <- substr(colnames(c4), 1, 6)
round(c4, digits = 4)

# Ratios between stardard errors.
cbind(GC = summary(c4[-1, 4]/c4[-1, 2]),
      TW = summary(c4[-1, 6]/c4[-1, 2]))
```


```{r, include = FALSE}
# V <- cov2cor(vcov(m1))
# corrplot.mixed(V,
#                lower = "number",
#                upper = "ellipse",
#                diag = "l",
#                tl.pos = "lt",
#                tl.col = "black",
#                tl.cex = 0.8,
#                col = brewer.pal(9, "Greys")
#                [-(1:3)]) dev.off()
```

None of the experimental factors had effect on the number of beans per
pod. Althought, Gamma-Count and Poisson-Tweedie showed more favorable
statistics to the rejection of the null hypothesis than Poisson.

```{r}
# Analysis of deviance table.
anova(m0, test = "Chisq")

# Wald test for interaction.
a <- c(0, attr(model.matrix(m0), "assign"))
ai <- a == max(a)
L <- t(replicate(sum(ai), rbind(coef(m1) * 0), simplify = "matrix"))
L[, ai] <- diag(sum(ai))
linearHypothesis(model = m0, # m0 is not being used here.
                 hypothesis.matrix = L,
                 vcov. = vcov(m1),
                 coef. = coef(m1))

# Wald test for fixed effects.
anova(m2)
```

Figure \@ref(fig:segplot-bp) shows the estimated cells means with 95%
confidence intervals. All estimated means are equals along models in
each cell.  Gamma-count and Poisson-Tweedie have more shorter confidence
intervals than Poisson.

```{r, include = FALSE}
#-----------------------------------------------------------------------
# Mean prediction.

# Because of the offset term, when can't use LSmatrix().
pred <- unique(subset(soja, select = c("umid", "K")))
X <- model.matrix(formula(m0)[-2],
                  data = cbind(nvag = 1, bloc = soja$bloc[1], pred))
i <- grep(x = colnames(X), pattern = "^bloc")
X[, i] <- X[, i] * 0 + 1/(length(i) + 1)
pred <- transform(pred,
                  K = as.numeric(as.character(K)),
                  umid = factor(umid))
pred <- list(P = pred, GC = pred, TW = pred)

# Poisson model prediction.
aux <- confint(glht(m0, linfct = X),
               calpha = univariate_calpha())$confint
colnames(aux)[1] <- "fit"
pred$P <- cbind(pred$P, exp(aux))

# Gamma-Count model prediction.
aux <- predict(m1, newdata = X,
               interval = "confidence",
               type = "link")
pred$GC <- cbind(pred$GC, exp(aux[, c(2, 1, 3)]))

V <- vcov(m2)
i <- grepl("^beta", rownames(V))
eta <- X %*% coef(m2, type = "beta")$Estimates
std <- sqrt(diag(as.matrix(X %*%
                           as.matrix(V[i, i]) %*%
                           t(X))))
q <- qnorm(0.975) * c(lwr = -1, fit = 0, upr = 1)
me <- outer(std, q, FUN = "*")
aux <- sweep(me, 1, eta, FUN = "+")
pred$TW <- cbind(pred$TW, exp(aux))

pred <- ldply(pred, .id = "model")
pred <- arrange(pred, umid, K, model)

key <- list(type = "o", divide = 1,
            lines = list(pch = 1:nlevels(pred$model),
                         lty = 1, col = 1),
            text = list(c("Poisson",
                          "Gamma-Count",
                          "Poisson-Tweedie")))
```
```{r segplot-bp, echo = FALSE, fig.cap = cap}
cap <- "Estimated cell means based on Poisson, Gamma-Count and Poisson-Tweedie regression models. Segments are 95% individual coverage confidence intervals."
xyplot(fit ~ K | umid,
       data = pred,
       layout = c(NA, 1),
       as.table = TRUE,
       xlim = extendrange(range(pred$K), f = 0.1),
       key = key,
       pch = pred$model,
       xlab = expression("Applied potassium amount" ~ (mg ~ dm^{-3})),
       ylab = "Number of beans per pod",
       ly = pred$lwr,
       uy = pred$upr,
       cty = "bars",
       length = 0,
       prepanel = prepanel.cbH,
       desloc = 8 * scale(as.integer(pred$model), scale = FALSE),
       panel = panel.cbH)
```

We analysed the number of beans por pod in a experiment with
soybeans. This variable showed underdispersion so Gamma-Count and
Poisson-Tweedie perform better than Poisson. <!-- TODO complementar -->


## Number of vehicle claims ##

```{r setup-claim, include=FALSE}

##----------------------------------------------------------------------
## load packages and functions
library(mcglm)
library(lattice)
library(latticeExtra)
library(gridExtra)
library(MRDCr)
library(multcomp)
library(plyr)

## The density of PTW dsitributions (using numerical integration)
library(statmod)
library(tweedie)
source("Script2.R")

```

Em companhias de seguros é de fundamental importância especificar um
preço adequado correspondente a um segurado, a fim de cobrir o risco
assumido. Tal tarefa geralmente envolve a avaliação de características
do plano de seguro que influenciam na taxa de sinistros observada.

Nesta seção nós apresentamos a análise de um conjunto do dados
referentes ao acompanhamento de `r nrow(seguros)` clientes de uma
seguradora de veículos ao longo de um ano. Os dados estão disponíveis no
pacote `MRDCr` (com documentação em português) e podem ser carregados
com

```{r, eval=FALSE}

##----------------------------------------------------------------------
## Load and organize data
data(package = "MRDCr")
help(seguros, h = "html")

```

Após a tradução dos níveis das variáveis categóricas a estrutura dos
dados fica

```{r, include=FALSE}

## Remove the unused variables
data(seguros, package = "MRDCr")
seguros <- seguros[, !colnames(seguros) %in% c("tipo", "civil")]

```

```{r}

## Translate levels of categorical variables and colnames
colnames(seguros) <- c("age", "sex", "price", "expo", "nclaims")
levels(seguros$sex) <- c("Female", "Male")
str(seguros)

```

In this dataset a variável `age` é mensurada em anos, e `price` em 1000
reais. A variável `expo` representa o período de cobertura do cliente,
durante o ano sob análise, um valor de 0.5 significa que o cliente
esteve exposto ao sinistro durante metade do ano.

```{r, include=FALSE}

## Proportion of null counts
p0 <- sum(seguros$nclaims == 0)*100/nrow(seguros)

```

A Figura \@ref(fig:desc-claim) mostra a descrição das variáveis a serem
utilizadas na análise. Embora esses gráficos não considerem todas as
variáveis conjuntamente, o gráfico à esquerda sugere que há um excesso
de contagens nulas, no geral  `r p0`% das contagens são 0.

```{r desc-claim, echo=FALSE, fig.width=8, fig.height=6, fig.cap=cap}

cap <- paste("Relative frequencies for number of vehicle claims,",
             "and empirical densities to price of vehicle, age of",
             "clients and exposure time by sex of insurance clients.")

##----------------------------------------------------------------------
## Descriptive analysis
cols <- trellis.par.get("superpose.polygon")$col
xy1 <- barchart(prop.table(xtabs(~nclaims + sex, data = seguros)),
                horizontal = FALSE,
                axis = axis.grid,
                xlab = "Number of vehicles claims",
                ylab = "Relative frequency",
                scales = list(y = list(rot = 90)))
xy2 <- barchart(prop.table(table(seguros$sex)),
                horizontal = FALSE,
                ylab = "",
                col = cols[1:2])
xy3 <- densityplot(~price, data = seguros,
                   groups = sex,
                   axis = axis.grid,
                   xlab = "price of vehicle (1000 R$)",
                   scales = list(y = list(rot = 90)))
xy4 <- densityplot(~age, data = seguros,
                   groups = sex,
                   axis = axis.grid,
                   xlab = "Age of insurance client (years)",
                   scales = list(y = list(rot = 90)))
xy5 <- densityplot(~expo, data = seguros,
                   groups = sex,
                   axis = axis.grid,
                   xlab = "Exposure time (years)",
                   scales = list(y = list(rot = 90)))

print(xy1, split = c(1, 1, 2, 2), more = TRUE)
print(xy2, position = c(0.15, 0.65, 0.48, 0.95), more = TRUE)
print(xy3, split = c(2, 1, 2, 2), more = TRUE)
print(xy4, split = c(1, 2, 2, 2), more = TRUE)
print(xy5, split = c(2, 2, 2, 2), more = FALSE)

```

Para análise desses dados consideramos efeitos quadráticos para
variáveis contínuas e intercepto variando conforme sexo do cliente.  `price` foi tomada como
preditor pode ser escrito como

\begin{equation*}
  \begin{split}
  \log\left ( \frac{\mu_i}{\texttt{expo}_i} \right ) = &
  \beta_0 + \beta_1 \mathbb{1}(\texttt{sex}_i) +
  \beta_2 \texttt{price}_i + \\
  & + \beta_3 \texttt{price}_i^2 +
  \beta_4 \texttt{age}_i +
  \beta_5 \texttt{age}_i^2
  \end{split}
\end{equation*}

em R definimos o preditor conforme sintaxe para objetos da classe
`formula`. Note que a variável `expo` é envolta na função `offset` e
sendo assim é considerado apenas como denominador das contagens.

```{r}

## Define preditor
form0 <- nclaims ~ offset(log(expo)) + sex +
    price + I(price^2) + age + I(age^2)

```

Nós ajustamos os modelos de regressão Poisson e Poisson-Tweedie usando
os frameworks `stats::glm` e `mcglm::mcglm`, que se baseam em máxima
verossimilhança e especificação por momentos respectivamente.

```{r fit-claim0}

## Fit Poisson
m0PO <- glm(form0, data = seguros, family = poisson)

## Fit Poisson-Tweedie
m0PT <- mcglm(
    linear_pred = c(form0),
    matrix_pred = list(mc_id(seguros)),
    link = "log",
    variance = "poisson_tweedie",
    power_fixed = FALSE,
    data = seguros)

```

Os parâmetros de regressão estimados nos modelos Poisson e
Poisson-Tweedie são exibidos abaixo juntamente com seus erros
padrão. Uma coluna com a razão entre as estimatimas e
erros-padrão é acrescida. Note que as estimativas muito similares e os
erros-Padrão são em torno de 20\% maiores quando considerado o modelo
Poisson-Tweedie.

```{r}

##----------------------------------------------------------------------
## Parameter estimates
parPO <- summary(m0PO)$coefficients[, 1:2]
parPT <- summary(m0PT)[[1]]$Regression[, 1:2]
pars <- cbind(parPO, parPT)
cbind(pars, cbind("RatioEst" = pars[, 3]/pars[, 1],
                  "RatioStd" = pars[, 4]/pars[, 2]))

```

Embora tenhamos ajustados os modelos e avaliados seus resultados, uma
suposição que é inerente ao modelo não foi avaliada. A inclusão do
offset (exposição) pressupõe relação identidade entre a exposição e o
número médio de sinistros ($\mu_i \texttt{expo}_i = \lambda_i$), em
outras palavras, sob as mesmas condições esperamos que um indivíduo com
tempo de exposição de $1$ ano tenha o dobro de sinistros do que um
indivíduo com tempo de exposição de $0.5$. A avaliação dessa suposição é
realizada estimando esse coeficiente e comparando-o com o valor fixado.

```{r, fit-claim1}

## Define preditors (free offset of first order and second order)
form1 <- nclaims ~ log(expo) + sex +
    price + I(price^2) + age + I(age^2)

## Fit Poisson
m1PO <- glm(form1, data = seguros, family = poisson)

## Fit Poisson-Tweedie
m1PT <- mcglm(linear_pred = c(form1),
          matrix_pred = list(mc_id(seguros)),
          link = "log",
          variance = "poisson_tweedie",
          power_fixed = FALSE,
          data = seguros)

```

Nos modelos Poisson o método `anova` em R realiza o teste de razão de
verossimilhanças para modelos aninhados.

```{r}

## Analysis of deviance table for nested models
(an <- anova(m0PO, m1PO, test = "Chisq"))

```

Com a estimação do coeficiente para $\log(\texttt{expo})$, houve uma
diferença de `r an$Deviance[2]` em relação ao modelo cujo coeficiente é
fixado em 1, evidenciando que a suposição de identidade entre o a
exposição e as contagens não é atendida.

Para os modelos Poisson-Tweedie os testes de razão de verossimilhanças
também são possíveis, porém tendem a ser computacionalmente intensivos
uma vez que a função de densidade é definida por uma integral
intratável. Sendo assim uma alternativa é comparar os modelos via
measures of Goodness-of-Fit que não precisam da verossimilhança like
pseudo Gaussian log-likelihood (plogLik), pseudo Akaike Information
Criterion (pAIC), pseudo Kullback-Leibler Information Criterion (pKLIC)
and Error Sum of Squares (ESS), que além de mais rápidas podem ser
utilizadas para o modelo Poisson-Tweedie estendido que não se baseia em
verossimilhança. Essas medidas são calculadas com função `mcglm::gof`.

```{r}

## Measures of goodness-of-fit for compare nested models
goflist <- lapply(list(m0PT, m1PT), gof)
(gofPT <- do.call("rbind", goflist))

```

Da mesma forma nos modelos Poisson-Tweedie também há fortes indicações
de que o coeficiente para o logarítimo das exposições não seja
$1$. Sendo assim seguimos as análises com os modelos que consideram a
estimação do efeito dos tempos de exposição.

As estimativas pontuais com erros-padrão são obtidas da mesma forma que
nos primeiros modelos ajustados. Note que não houve uma mudança drástica
nas estimativas comparando ao modelo com offset, indicando que não há
relação entre os tempos de exposição e as covariáveis. A similaridade
das estimativas do modelo Poisson e Poisson-Tweedie se mantém assim como
o aumento em 20\% nos erros-padrão.

```{r}

##----------------------------------------------------------------------
## Parameter estimates
parPO <- summary(m1PO)$coefficients[, 1:2]
parPT <- summary(m1PT)[[1]]$Regression[, 1:2]
pars <- cbind(parPO, parPT)
cbind(pars, cbind("RatioEst" = pars[, 3]/pars[, 1],
                  "RatioStd" = pars[, 4]/pars[, 2]))

```

```{r, include=FALSE}

co <- coef(m1PO)

```

Finalmente a Figura \ref@(fig:claims-pred) apresenta as curvas de
predição conforme cada variável, como temos mais de uma covariável
numérica no modelo, fixamos as demais variáveis seu valor mediano para
construção das curvas. O efeito quadrático das variáveis `price` e `age`
é evidente. A média de sinistros é maior para veículos entre 50 e 100
mil reais, veículos de valores baixos ou muito elevados tendem a ter um
taxa de sinistros menor, o que faz sentido no mercado brasileiro onde
furtos e acidentes ocorrem com maior frequência em carros
populares. Para a idade temos a interpretação contrária, espera-se menos
sinistros para idades medianas, entre 40 e 70 anos e maiores para jovens
e idosos.

Comparando os modelos temos curvas de predição e intervalos de confiança
muito similares, sendo levemente maiores quando considerado o
Poisson-Tweedie. O que se destaque no gráfico é a diferença nos
intervalos de confiança para o preço do veículo, nesse caso o modelo
Poisson-Tweedie é muito mais conservador onde há menos observações, no
intervalo de preços mais elevados.

```{r claims-pred, fig.width=8, fig.height=5}

cap <- paste("Curves of predict values an confidence intervals (95\\%)",
             "based on Poisson and Poisson-Tweedie regression models",
             "for each numerical covariate setting the others in the",
             "median.")

##-------------------------------------------
## Prediction to exposure
aux <- with(seguros, {
    expand.grid(
        expo = seq(min(expo), max(expo), length.out = 30),
        sex = unique(sex),
        price = median(price),
        age = median(age)
    )
})

da <- data.frame(var = "Exposure", x = aux$expo, sex = aux$sex)
X <- model.matrix(update(form1, NULL ~ .), data = aux)
pred <- list(PO = da, PT = da)

## Poisson model
aux <- confint(glht(m1PO, linfct = X),
               calpha = univariate_calpha())$confint
colnames(aux)[1] <- "fit"
pred$PO <- cbind(pred$PO, exp(aux)[, c("lwr", "fit", "upr")])

## Poisson-Tweedie model
qn <- qnorm(0.975) * c(lwr = -1, fit = 0, upr = 1)
V <- vcov(m1PT)
i <- grepl("beta", colnames(V))
eta <- X %*% coef(m1PT, type = "beta")$Estimates
std <- sqrt(diag(as.matrix(X %*% as.matrix(V[i, i]) %*% t(X))))
me <- outer(std, qn, FUN = "*")
aux <- sweep(me, 1, eta, FUN = "+")
pred$PT <- cbind(pred$PT, exp(aux))

## Organize predictions
predsex <- ldply(pred, .id = "model")

##-------------------------------------------
## Prediction to price
aux <- with(seguros, {
    expand.grid(
        expo = median(expo),
        sex = unique(sex),
        price = seq(min(price), max(price), length.out = 30),
        age = median(age)
    )
})

da <- data.frame(var = "Price", x = aux$price, sex = aux$sex)
X <- model.matrix(update(form1, NULL ~ .), data = aux)
pred <- list(PO = da, PT = da)

## Poisson model
aux <- confint(glht(m1PO, linfct = X),
               calpha = univariate_calpha())$confint
colnames(aux)[1] <- "fit"
pred$PO <- cbind(pred$PO, exp(aux)[, c("lwr", "fit", "upr")])

## Poisson-Tweedie model
qn <- qnorm(0.975) * c(lwr = -1, fit = 0, upr = 1)
V <- vcov(m1PT)
i <- grepl("beta", colnames(V))
eta <- X %*% coef(m1PT, type = "beta")$Estimates
std <- sqrt(diag(as.matrix(X %*% as.matrix(V[i, i]) %*% t(X))))
me <- outer(std, qn, FUN = "*")
aux <- sweep(me, 1, eta, FUN = "+")
pred$PT <- cbind(pred$PT, exp(aux))

## Organize predictions
predspr <- ldply(pred, .id = "model")

##-------------------------------------------
## Prediction to age
aux <- with(seguros, {
    expand.grid(
        expo = median(expo),
        sex = unique(sex),
        price = median(price),
        age = seq(min(age), max(age), length.out = 30)
    )
})

da <- data.frame(var = "Age", x = aux$age, sex = aux$sex)
X <- model.matrix(update(form1, NULL ~ .), data = aux)
pred <- list(PO = da, PT = da)

## Poisson model
aux <- confint(glht(m1PO, linfct = X),
               calpha = univariate_calpha())$confint
colnames(aux)[1] <- "fit"
pred$PO <- cbind(pred$PO, exp(aux)[, c("lwr", "fit", "upr")])

## Poisson-Tweedie model
qn <- qnorm(0.975) * c(lwr = -1, fit = 0, upr = 1)
V <- vcov(m1PT)
i <- grepl("beta", colnames(V))
eta <- X %*% coef(m1PT, type = "beta")$Estimates
std <- sqrt(diag(as.matrix(X %*% as.matrix(V[i, i]) %*% t(X))))
me <- outer(std, qn, FUN = "*")
aux <- sweep(me, 1, eta, FUN = "+")
pred$PT <- cbind(pred$PT, exp(aux))

## Organize predictions
predsag <- ldply(pred, .id = "model")

##-------------------------------------------
## Graph
preds <- rbind(predsex, predspr, predsag)
useOuterStrips(
    xyplot(fit ~ x | var + sex,
           data = preds,
           groups = model,
           type = c("g", "l"),
           ly = preds$lwr, uy = preds$upr,
           layout = c(NA, 1),
           as.table = TRUE,
           alpha = 0.2,
           xlab = "Value of covariate",
           ylab = "Mean of vehicles claims",
           ## scales = list(x = "free"),
           scales = "free",
           auto.key = list(
               columns = 2,
               lines = TRUE,
               points = FALSE,
               text = c("Poisson", "Poisson-Tweedie")
           ),
           cty = "bands", fill = "gray80",
           panel = panel.superpose,
           panel.groups = panel.cbH,
           prepanel = prepanel.cbH)
)

```

Para avaliar o poder preditivo dos modelos nós calculamos as frequências
estimadas pelos dois modelos considerados e comparamos com as
observadas. As frequências estimadas $\hat{\mathrm{Fr}}$, para um dado
valor $y$ são calculadas como

```{r, include=FALSE}

phi <- with(coef(m1PT), Estimates[Type == "tau"])
power <- with(coef(m1PT), Estimates[Type == "power"])

```

$$
\hat{\mathrm{Fr}}(y) = \sum_{i=1}^n \Pr(Y=y \mid \boldsymbol{\hat{\theta}}_i)
$$

Onde $\Pr(Y=y \mid \hat{\boldsymbol{\theta}}_i)$ é a função massa de
probabilidade definida pelo conjunto de parâmetros
$\boldsymbol{\hat{\theta}}_i$. Para o modelo Poisson
$\hat{\boldsymbol{\theta}}_i = \hat{\mu}_i$ e para o modelo
Poisson-Tweedie $\hat{\boldsymbol{\theta}}_i =
[\hat{\mu}_i \hat{\phi}=`r phi`] \hat{p}=`r power`]$. For
Poisson-Tweedie model we evaluate the integral using the Gauss-Laguerre
method (with 100 points). The results shows that Poisson-Tweedie model
offers a better fit with adjust frequencies very close of observed
frequencies.

```{r freqs-claim, eval=FALSE}

## Adjust frequencies by models

## Calcule probabilities
X <- model.matrix(form1, data = seguros)
y <- 0:6
n <- nrow(seguros)
freqs <- list()

## Observed
freqs$Obs <- with(seguros, sapply(y, function(x) {
    sum(nclaims == x)
}))

## By Poisson
muPO <- exp(X %*% coef(m1PO))
probsPO <- do.call(
    "rbind",
    lapply(muPO, function(mui) {
        py <- dpois(y, lambda = mui)
    }))
freqs$PO <- round(apply(probsPO, 2, sum))

## By Poisson-Tweedie
##  -- very time consuming.
muPT <- exp(X %*% coef(m1PT, type = "beta")$Estimates)
phi <- with(coef(m1PT), Estimates[Type == "tau"])
power <- with(coef(m1PT), Estimates[Type == "power"])
probsPT <-do.call(
    "rbind",
    lapply(muPT, function(mui) {
        py <- dptw(y = y, mu = mui, phi = phi,
                   power = power, n_pts = 100,
                   method = "laguerre")
    }))
freqs$PT <- round(apply(probsPT, 2, sum))
tabf <- ldply(freqs)

colnames(tabf) <- c("", y)
tabf

```

```{r, echo=FALSE}

load("cache/tabf-claims.rda")
tabf

```

## Radiation-induced chromosome aberration counts ##

```{r setup-chromo, include=FALSE}

##----------------------------------------------------------------------
## load packages and functions
library(mcglm)
library(lattice)
library(latticeExtra)
library(gridExtra)
library(MRDCr)
library(multcomp)
library(plyr)

## The density of PTW dsitributions (using numerical integration)
library(statmod)
library(tweedie)
source("Script2.R")

```

In biological dosimetry studies essentially the response variables are
data counts. These experiments measure the number of chromosome
aberrations in human lymphocytes after to controlled exposure of
ionizing radiation. The aim of the studies are analyse the biological
effects induced by ionizing radiation. The aberrations most commonly
mensured are the dicentrics, centric rings, and micronucle .

In this section the dataset considered was obtained after irradiating
blood samples with five different doses between 0.1 and 1 Gy of 2.1 MeV
neutrons. In this case, the frequencies of dicentrics and centric rings
after a culture of 72 hours are analysed. The dataset was analysed by
@Oliveira2006, as an example of zero-inflated data and @Bonat2016b,
using extend Poisson-Tweedie approach.

The data are available in `data/chromossome.rda` file. In `R` it can be
loaded with

```{r}

##----------------------------------------------------------------------
## Load
load("./data/chromosome.rda")
str(chromosome)

```

The Figure \@ref(fig:desc-chromo) shows the frequencies chromosome
aberrations (left) and average of chromosome aberrations by radiation
doses (right). Note that the highest frequencies are observed for zero
counts and the averages are between 0 and 1, suggesting excess zero.

```{r desc-chromo, fig.width=9, fig.height=4, fig.cap = cap, echo=FALSE}

cap <- paste("Observed frequencies of the chromosome aberrations",
             "counts by radiation doses (left) and means of chromosome",
             "aberrations for each radiation doses (right).")

##----------------------------------------------------------------------
## Descriptive analysis

## Frequencies
xt <- xtabs(~ndic + dose, data = chromosome)
xy1 <- barchart(xt,
                axis = axis.grid,
                stack = FALSE,
                horizontal = FALSE,
                xlab = "Number of chromosome aberrations",
                ylab = "Frequency",
                auto.key = list(
                    title = "Radiation doses",
                    cex.title = 1.1,
                    column = 3
                ))

## Means
mobs <- with(chromosome,
             data.frame("means" = tapply(ndic, dose, mean),
                        "doses" = unique(dose)))
xy2 <- xyplot(means ~ doses,
              data = mobs,
              pch = 19,
              type = c("p", "g", "o"),
              xlab = "Radiation doses",
              ylab = "Mean of chromosome aberrations")

print(xy1, split = c(1, 1, 2, 1), more = TRUE)
print(xy2, split = c(2, 1, 2, 1), more = FALSE)

```

For this application we fit the Poisson, Gamma-Count, COM-Poisson and
Poisson-Tweedie distributions. The linear predictor considered is a
quadratic dose model, follow @Bonat2016b. The codes below fit the four
models using the `MRDCd` and `mcglm` packages. Note that for
`MRDCr::cmp` function we need specify `sumto`, the number of increments
for a infinite sum, i.e in this case $Z(\hat{\lambda}_i, \hat{\nu}) =
\sum_j^{50}\hat{\lambda}_i^j / (j!)^{\hat{\nu}}$.

```{r model-chromo}

##----------------------------------------------------------------------
## Modelling
form <- ndic ~ dose + I(dose^2)

m0PO <- glm(form, family = poisson, data = chromosome)
m0GC <- gcnt(form, data = chromosome)
m0CP <- cmp(form, data = chromosome, sumto = 50)
m0PT <- mcglm(
    linear_pred = c(form),
    matrix_pred = list(mc_id(chromosome)),
    link = "log",
    variance = "poisson_tweedie",
    power_fixed = FALSE,
    data = chromosome)

```

No issues were reported during the estimation process. A better research
about the algorithm covergence for Poisson-Tweedie models is implemented
by `mcglm::plot(model, type = "algorithm")`. This four graphs shows the
trajectory or iterations of the fitting algorithm, we can see that both
cases the lines converged.

```{r conv-chromo}

## Check algorithm convergence
plot(m0PT, type = "algorithm")

```

For the COM-Poisson and Gamma-Count we can see the `details` slots,
(`model@details`). This shows the components list of `optim`, the list
object `convergence` when 0 means that optimization was successful and
`counts` shows the number of calls to log-likelihood function and
numerical gradient function. Note the in this case the COM-Poisson model
required fewer interactions than Gamma-Count model. However, we don't
evaluate the time of fit because to compute log-likelihood function for
COM-Poisson is more difficult than for Gamma-Count.

```{r}

## Check optim convergence
do.call("rbind",
        lapply(list("GC" = m0GC, "CP" = m0CP),
               function(model) {
                   c(model@details$counts,
                     "convergence" = model@details$convergence)
               }))

```

For COM-POisson model, we also need verify that the number of increments
for $Z(\hat{\lambda}_i, \hat{\nu})$ is satisfactory for accurate
sums. The function `MRDCr::covergencez` shows a number of increments
necessary for a given tolerance. For each line represent the $i$th
observation, as we only have five different doses only five lines are
showed. Note that the `sumto=50` is more than necessary for the
convergence of all constansts.

```{r}

## Check Z(lambda, nu) convergence
convergencez(m0CP, tol = 1e-5)

```

```{r, include=FALSE}

power <- with(coef(m0PT), Estimates[Type == "power"])

```

For compare models we used the log-likelihood value and AIC and BIC
criteria. In the Gamma-Count and COM-Poisson the measures are easily
obtained by `logLik`, `AIC` and `BIC` functions. In the Poisson-Tweedie
model this functions are not implemented, because the models are
estimated only by second-moments assumptions. However, in this case we
can compute log-likelihood, and consequently AIC and BIC criteria. This
is possible beacause the parameter $p$ was estimated on `r power`. The
codes below compute these measures for the four models. Note that in R
we only implement `logLik.mcglm` function, the other functions `AIC` and
`BIC` are methods for `logLik` objects.

The measures of goodness-of-fit show that Poisson-Tweedie approach is
more suitable in this case. Gamma-Count and COM-Poisson models present
similar results and Poisson model the worse results. This is attributed
to the inadequate assumption of equidespersion and excess of zeros.

```{r gof-chromo}

##----------------------------------------------------------------------
## Goodness of fit

## Compute logLik for Poisson-Tweedie
##    ** especific for this example
logLik.mcglm <- function(object) {
    y <- c(0:5, 7)
    data <- data.frame(dose = unique(chromosome$dose))
    ## ---
    form <- update(object$linear_pred[[1]], NULL ~ .)
    X <- model.matrix(form, data)
    mu <- exp(X %*% coef(object, type = "beta")$Estimates)
    phi <- with(coef(object), Estimates[Type == "tau"])
    power <- with(coef(object), Estimates[Type == "power"])
    obs <- xtabs(~ndic + dose, data = chromosome)
    matpred <- do.call("cbind", lapply(mu, function(mui) {
        dptw(y = y, mu = mui, phi = phi, power = power,
             n_pts = 180, "laguerre")
    }))
    ll <- sum(log(matpred) * obs)
    attr(ll, "df") <- nrow(coef(object))
    attr(ll, "nobs") <- m0PT$n_obs
    class(ll) <- "logLik"
    return(ll)
}

## Compute table of gof
models <- list("Poisson" = m0PO, "Gamma-Count" = m0GC,
               "COM-Poisson" = m0CP, "Poisson-Tweedie" = m0PT)
(measures <- sapply(models, function(x)
    c("LogLik" = logLik(x), "AIC" = AIC(x), "BIC" = BIC(x))))

```

The parameters estimates can be obtained by `summary` methods. The codes
below shows the estimates of location and dispersion parameters. Note
that the estimates for the location parameters were very close in
Poisson, COM-Poisson and Poisson-Tweedie. For the Gamma-Count model the
estimates are many differents though the signs are the same. Regarding
the standard deviations, we have the Poisson and COM-Poisson very close,
Poisson-Tweedie with standard deviations a little bigger and the
Gamma-Count much bigger than others, totally dissagre.

```{r}

##----------------------------------------------------------------------
## Parameter estimates
par <- list()
par$PO <- rbind(NA, summary(m0PO)$coefficients[, 1:2])
par$GC <- summary(m0GC)@coef[, 1:2]
par$CP <- summary(m0CP)@coef[, 1:2]
par$PT <- rbind(summary(m0PT)[[1]]$tau[, 1:2],
               summary(m0PT)[[1]]$Regression[, 1:2])

do.call("cbind", par)

```

The predict values with confidence intervals are calculated with matrix
operations, using delta method for confidence intervals. The results
for all models are presents in Figure \@ref(fig:pred-chromo) together
with the observed values (black points). Though the estimates parameters
are very different the other models, for Gamma-Count the pontual
prediction is consistent with others. However, the confidence intervals
for Gamma-Count are much more conservative.

The practical interpretation of the results in \@ref(fig:pred-chromo) is
that the chromosome aberration in blood samples increase as doses.
However the increase does not have the same intensity for all doses.

```{r pred-chromo, echo=FALSE}

##----------------------------------------------------------------------
## Estimation

##----------------------------------------------------------------------
## Prediction
aux <- with(chromosome, {
    data.frame(dose = seq(min(dose), max(dose), length.out = 28))
})
X <- model.matrix(update(form, NULL ~ .), data = aux)
pred <- list(PO = aux, GC = aux, CP = aux, PT = aux)

## Poisson model
aux <- confint(glht(m0PO, linfct = X),
               calpha = univariate_calpha())$confint
colnames(aux)[1] <- "fit"
pred$PO <- cbind(pred$PO, exp(aux)[, c("lwr", "fit", "upr")])

## Gamma-Count model
aux <- predict(m0GC, newdata = X, interval = "confidence",
                  type = "response")
pred$GC <- cbind(pred$GC, aux)

## COM-Poisson model
aux <- predict(m0CP, newdata = X, interval = "confidence",
                  type = "response")
pred$CP <- cbind(pred$CP, aux)

## Poisson-Tweedie model
qn <- qnorm(0.975) * c(lwr = -1, fit = 0, upr = 1)
V <- vcov(m0PT)
i <- grepl("beta", colnames(V))
eta <- X %*% coef(m0PT, type = "beta")$Estimates
std <- sqrt(diag(as.matrix(X %*% as.matrix(V[i, i]) %*% t(X))))
me <- outer(std, qn, FUN = "*")
aux <- sweep(me, 1, eta, FUN = "+")
pred$PT <- cbind(pred$PT, exp(aux))

## Organize predictions
preds <- ldply(pred, .id = "model")

```

```{r mean-chromo, fig.cap=cap}

cap <- paste("Dispersion diagram of observed chromossome aberrations and",
             "curves of predict values an confidence intervals (95\\%)",
             "based on Poisson, Gamma-Count, COM-Poisson and",
             "Poisson-Tweedie regression models.")

##-------------------------------------------
## Visualize means

## pred2 <- subset(preds, model %in% c("PO", "PT"))
xyplot(fit ~ dose,
       data = preds,
       groups = model,
       type = c("g", "l"),
       ly = preds$lwr, uy = preds$upr,
       layout = c(NA, 1),
       as.table = TRUE,
       alpha = 0.2,
       xlab = "Radiation doses",
       ylab = "Mean of chromosomic aberrations",
       auto.key = list(
           columns = 2,
           lines = TRUE,
           points = FALSE,
           text = c("Poisson", "Gamma-Count",
                    "COM-Poisson", "Poisson-Tweedie")
       ),
       cty = "bands", fill = "gray80",
       panel = panel.superpose,
       panel.groups = panel.cbH,
       prepanel = prepanel.cbH) +
    as.layer(
        update(xy2, type = "p")
    )

```

To complement the study we compute the probability distribution for the
five doses used in the experiment. This distributions are presents in
Figure \@ref(fig:probs-chromo). Note that for 0.1Gy of 2.1MeV dose
neutrons the probabilities are strongly concentrated in 0 count, for
1Gy of 2.1MeV dose the distributions still strongly assymmetric on the
right, but the probabilities are more dispersed. It is worth mentioning
that all distribuitions, thought different, are the same average.

```{r probs-chromo, fig.cap="Adjust probability distribution for the chromossome aberrations counts by five irradiation doses."}

##-------------------------------------------
## Calcule probabilities
index <- preds$dose %in% unique(chromosome$dose)
means <- preds[index, c("model", "dose", "fit")]
probs <- list()
y <- 0:5

## Poisson model
indPO <- grep("PO", means$model)
probs$PO <- do.call(
    "rbind",
    lapply(indPO, function(i) {
        with(means, {
            py <- dpois(y, fit[i])
            data.frame(dose = dose[i], y = y, prob = py)
        })
    })
)

## Gamma-Count model
indGC <- grep("GC", means$model)
alpha <- exp(coef(m0GC)["alpha"])
probs$GC <- do.call(
    "rbind",
    lapply(indGC, function(i) {
        with(means, {
            aux <- predict(m0GC, newdata = t(cbind(X[i, ])),
                           type = "link")
            lambda <- alpha %*% exp(aux)
            py <- dgcnt(y, lambda = lambda, alpha = alpha)
            data.frame(dose = dose[i], y = y, prob = py)
        })
    })
)

## COM-Poisson model
indCP <- grep("CP", means$model)
nu <- exp(coef(m0CP)["phi"])
sumto <- m0CP@data$sumto
probs$CP <- do.call(
    "rbind",
    lapply(indCP, function(i) {
        with(means, {
            aux <- predict(m0CP, newdata = t(cbind(X[i, ])),
                           type = "link")
            lambda <- exp(aux)
            py <- dcmp(y, lambda = lambda, nu = nu, sumto = sumto)
            data.frame(dose = dose[i], y = y, prob = py)
        })
    })
)

## Poisson-Tweedie model
indPT <- grep("PT", means$model)
phi <- with(coef(m0PT), Estimates[Type == "tau"])
power <- with(coef(m0PT), Estimates[Type == "power"])
probs$PT <- do.call(
    "rbind",
    lapply(indPT, function(i) {
        with(means, {
            py <- dptw(y = y, mu = fit[i], phi = phi,
                       power = power, n_pts = 180,
                       method = "laguerre")
            data.frame(dose = dose[i], y = y, prob = py)
        })
    })
)

## Visualize the probabilities
daprobs <- ldply(probs, .id = "model")

barchart(prob ~ y | factor(dose), groups = model,
         data = daprobs,
         horizontal = FALSE,
         axis = axis.grid,
         as.table = TRUE,
         origin = 0,
         xlab = "Number of chromosomic aberrations",
         ylab = "Probability",
         scales = list(x = list(labels = y)),
         auto.key = list(
             columns = 2,
             text = c("Poisson", "Gamma-Count",
                      "COM-Poisson", "Poisson-Tweedie")
         ),
         strip = strip.custom(
             strip.name = TRUE,
             var.name = "dose",
             sep = " = "
         ))

```

```{r}
str(nematoide)

xyplot(nema/off ~ cult, data = nematoide,
       xlab = "Linhagens de feijão",
       ylab = "Número de nematoides por grama de raíz")

m0 <- glm(nema ~ offset(log(off)) + cult,
          data = nematoide,
          family = poisson)
m1 <- update(m0, family = quasipoisson)
summary(m1)

# Diagnóstico.
par(mfrow = c(2, 2))
plot(m0); layout(1)

m2 <- mcglm(linear_pred = c(nema ~ cult),
            matrix_pred = list(mc_id(data = nematoide)),
            link = "log",
            offset = list(log(nematoide$off)),
            variance = "poisson_tweedie",
            power_fixed = FALSE,
            data = nematoide,
            control_algorithm = list(verbose = FALSE,
                                     max_iter = 100,
                                     tunning = 0.5,
                                     correct = FALSE))
summary(m2)
```
```{r, results = "hide"}
c0 <- summary(m0)$coefficients[, 1:2]
c1 <- summary(m1)$coefficients[, 1:2]
c2 <- rbind(summary(m2)[[1]]$tau[, 1:2],
            summary(m2)[[1]]$Regression[, 1:2])
```
```{r}
# Parameter estimates according to each model.
c4 <- cbind("P" = rbind(NA, c0),
            "QP" = rbind(c(summary(m1)$dispersion, NA), c1),
            "TW" = c2)
colnames(c4) <- substr(colnames(c4), 1, 6)
round(c4, digits = 4)

# Ratios between stardard errors.
cbind(GC = summary(c4[-1, 4]/c4[-1, 2]),
      TW = summary(c4[-1, 6]/c4[-1, 2]))
```

```{r, include = FALSE}
#-----------------------------------------------------------------------
# Mean prediction.

# Cell combinations.
pred <- data.frame(cult = factor(levels(nematoide$cult)))
X <- model.matrix(~cult, data = pred)
pred <- list(P = pred, QP = pred, TW = pred)

# Poisson model prediction.
aux <- confint(glht(m0, linfct = X),
               calpha = univariate_calpha())$confint
colnames(aux)[1] <- "fit"
pred$P <- cbind(pred$P, exp(aux))

# Quasi Poisson.
aux <- confint(glht(m1, linfct = X),
               calpha = univariate_calpha())$confint
colnames(aux)[1] <- "fit"
pred$QP <- cbind(pred$QP, exp(aux))

V <- vcov(m2)
i <- grepl("^beta", rownames(V))
eta <- X %*% coef(m2, type = "beta")$Estimates
std <- sqrt(diag(as.matrix(X %*%
                           as.matrix(V[i, i]) %*%
                           t(X))))
q <- qnorm(0.975) * c(lwr = -1, fit = 0, upr = 1)
me <- outer(std, q, FUN = "*")
aux <- sweep(me, 1, eta, FUN = "+")
pred$TW <- cbind(pred$TW, exp(aux))

pred <- ldply(pred, .id = "model")
pred <- arrange(pred, cult, model)

key <- list(type = "o", divide = 1,
            lines = list(pch = 1:nlevels(pred$model),
                         lty = 1, col = 1),
            text = list(c("Poisson",
                          "Quasi-Poisson",
                          "Poisson-Tweedie")))
```
```{r segplot-nema, echo = FALSE, fig.cap = cap}
cap <- "Estimated cell means based on Poisson, Gamma-Count and Poisson-Tweedie regression models. Segments are 95% individual coverage confidence intervals."
xyplot(fit ~ cult,
       data = pred,
       pch = pred$model,
       ly = pred$lwr,
       uy = pred$upr,
       cty = "bars",
       length = 0,
       prepanel = prepanel.cbH,
       desloc = 0.15 * scale(as.integer(pred$model),
                             scale = FALSE),
       panel = panel.cbH)
```

```{r}
curve(x + 4.21 * x^0.5, 0, 50, asp = 1,
      xlab = expression(mu),
      ylab = expression(mu + phi * mu^p))
abline(a = 0, b = 1, lty = 2)
```
