<<setup-childSection2, include=FALSE>>=
## set_parent("slides-mrdcr.Rnw")

## Pacotes utilizados nesta seção

@

\subsection{Distribuição Poisson}

%%%-------------------------------------------------------------------
\begin{frame}{Distribuição Poisson}
\begin{itemize}
\item Função de probabilidade
\begin{eqnarray}
f(y;\mu) &=& \frac{\mu^y}{y!}\exp\{-\mu\} \nonumber \\
	     &=& \frac{1}{y!} \exp \{\phi y -  \exp\{\phi\} \}, \quad y \in \mathbb{N}_{0},
\end{eqnarray}
onde $\phi = \log \{\mu\} \in \mathbb{R}$ e $\kappa(\phi) = \exp\{\phi\}$
denota a função cumulante.
\vspace{0,5cm}
\item $\mathrm{E}(Y) = \kappa^{\prime}(\phi) = \exp\{\phi\} = \mu$. 
\vspace{0,5cm}
\item $\mathrm{var}(Y) = \kappa^{\prime \prime}(\phi) = \exp\{\phi\} = \mu$.
\vspace{0,5cm}
\item Em \texttt{R} temos \texttt{dpois()}.

\end{itemize}
\end{frame}

%%%-------------------------------------------------------------------
\begin{frame}{Regressão Poisson}
\begin{itemize}
\item Considere $(y_i, x_i)$, $i = 1,\ldots, n$, onde $y_i$'s são iid 
realizações de $Y_i$ de acordo com a distribuição Poisson.
\vspace{0,5cm}
\item Modelo de regressão Poisson
$$Y_i \sim P(\mu_i), \quad  \text{sendo} \quad \mu_i = g^{-1}(\boldsymbol{x_i}^{\top} \boldsymbol{\beta}),$$
onde $\boldsymbol{x_i}$ and $\boldsymbol{\beta}$ são vetores $(p \times 1)$
de covariáveis conhecidas e parâmetros de regressão.
\vspace{0,5cm}
\item Em \texttt{R} temos \texttt{glm(..., family = poisson)}.
\vspace{0,5cm}
\item $g$ função de ligação (log link).
\end{itemize}
\end{frame}

%%%-------------------------------------------------------------------
\subsection{Distribuição Gamma-Count}

\begin{frame}
  \begin{center}
    \includegraphics[width=11cm]{images/winkelman95.jpeg}
  \end{center}
  \begin{thebibliography}{99}
  \bibitem{Winkelmann1995}
    \MakeUppercase{Winkelmann, R.}
    \newblock{Duration Dependence and Dispersion in Count-Data Models}.
    \textbf{Journal of Business \& Economic Statistics}, v.13, n.4,
    p.467--474, 1995.
  \end{thebibliography}
\end{frame}

%%%-------------------------------------------------------------------
\begin{frame}
  \frametitle{Duração dependência}
  \begin{itemize}
  \item Considere um processo estocástico definido pela sequência da
    va $\tau_k$, intervalo de tempo entre eventos.
  \item Se $\{\tau_1, \tau_2,\ldots\}$ são independentes e identicamente
    distribuídos, todos com densidade $f(\tau)$, esse processo é chamado
    de \emph{renewal process}.
  \item Defina a variável de contagem $Y_T$ como o número de eventos no
    intervalo $[0,T)$.
  \item Defina $\vartheta_y = \sum_{k=1}^{y} \tau_k$ o tempo até o
    $y$-ésimo evento.
  \item A distribuição de $\vartheta_y$ determina a distribuição de
    $Y_T$, mas é baseada em convolução.
  \item São distribuições fechadas para convolução: normal, Poisson,
    binomial e gama.
  \item Destas, apenas a gama é contínua e positiva.
  \end{itemize}
\end{frame}

%%%-------------------------------------------------------------------
\begin{frame}[allowframebreaks]
  \frametitle{Relação entre número de eventos e intervalo entre eventos}
  \begin{itemize}
  \item Intervalos entre tempo $\tau_k \sim \text{G}(\alpha,\gamma)$,
  (omitindo $k$) temos
    $$f(\tau, \alpha, \gamma) = \frac{\gamma^\alpha}{\Gamma(\alpha)}
    \cdot \tau^{\alpha-1}\cdot \exp\{-\gamma\tau\},$$
    $$ \text{E}(\tau) = \frac{\alpha}{\gamma}, \quad
    \text{var}(\tau) = \frac{\alpha}{\gamma^2}.$$
  \item Tempo até o $y$-ésimo evento
    $$\vartheta_y = \tau_1+\cdots+\tau_y ~ \sim
    \text{G}(y\alpha, \gamma),$$
    $$f_y(\vartheta, \alpha, \gamma) =
    \frac{\gamma^{y\alpha}}{\Gamma(y\alpha)}\cdot
    \vartheta^{y\alpha-1}\cdot \exp\{-\gamma\vartheta\},$$
    $$ \text{E}(\vartheta) = \frac{y\alpha}{\gamma}, \quad
    \text{var}(\vartheta) = \frac{y\alpha}{\gamma^2}.$$

    \framebreak

  \item A distribuição acumulada do tempo até $\vartheta_{y}$ é
    $$F_y(T) = \Pr(\vartheta_y \leq T) = \int_{0}^{T}
    \frac{\gamma^{y\alpha}}{\Gamma(y\alpha)}\cdot t^{y\alpha-1}\cdot
    \exp\{-\gamma t\}\,\text{d}t.$$
  \item Seja $[0,T)$ um intervalo e $Y_{T}$ a va número de eventos
    neste intervalo.
  \item Segue que $Y_T < y$ se e somente se $\vartheta_y \geq
    T$. Assim
    $$\Pr(Y_T < y) = \Pr(\vartheta_y \geq T) = 1-F_y(T);$$
  \item Já que $\Pr(Y_T = y) = \Pr(Y_T < y+1) - \Pr(Y_T < y)$, então
    $$\Pr(Y_T = y) = F_y(T) - F_{y+1}(T).$$

    \framebreak

  \item Portanto, distribuição de $Y_T$ é resultado da diferença de
    acumuladas da distribuição Gama, 
    \begin{equation}
      F_y(T) = G(y\alpha, \gamma T) =
      \int_{0}^{T} \frac{\gamma^{y\alpha}}{\Gamma(y\alpha)}
      t^{y\alpha-1}\cdot\exp\{-\gamma t\}\, \text{d}t.
    \end{equation}
  \item Assim
    \begin{align*}
      \Pr(Y_T=y) &= G(y\alpha, \gamma T) - G((y+1)\alpha, \gamma T) \\
                 &= \left[ \int_{0}^{T}
                   \frac{\gamma^{y\alpha}}{\Gamma(y\alpha)}
                   t^{y\alpha-1}\cdot
                   \exp\{-\gamma t\}\, \text{d}t \right] \\
                 &\quad -
                   \left[ \int_{0}^{T}
                   \frac{\gamma^{(y+1)\alpha}}{\Gamma((y+1)\alpha)}
                   t^{(y+1)\alpha-1}\cdot
                   \exp\{-\gamma t\}\, \text{d}t \right].
    \end{align*}
  \end{itemize}
\end{frame}

%%%-------------------------------------------------------------------
\begin{frame}[fragile]
  \frametitle{Função de probabilidade}
  \begin{itemize}
  \item Em \texttt{R} temos

<<echo=TRUE, tidy=TRUE>>=
dgc <- function(y, gamma, alpha, log = FALSE) {
  p <- pgamma(q = 1,
              shape = y * alpha,
              rate = alpha * gamma) -
    pgamma(q = 1,
           shape = (y + 1) * alpha,
           rate = alpha * gamma)
  if(log == TRUE) {p <- log(p)}
  return(p)
}

@

\end{itemize}
\end{frame}
%%%-------------------------------------------------------------------

%%%-------------------------------------------------------------------
\begin{frame}[fragile]
\begin{figure}[h]
\includegraphics[scale=0.6]{images/GammaCount.png}
\caption{Função de probabilidade de acordo com valores do índice de dispersão - Gamma-Count.}
\label{Fig2}
\centering
\end{figure}
\begin{itemize}
\item Índice de dispersão - $\mathrm{DI} =  \mathrm{E}(Y)/\mathrm{var}(Y)$
\end{itemize}
\end{frame}

%%%-------------------------------------------------------------------
\begin{frame}[allowframebreaks]
  \frametitle{Parametrização para modelo de regressão}
  \begin{itemize}
  \item A média da variável aleatória $Y_T$ é resultado de
    \begin{align*}
      \mathrm{E}(Y_T) &= \sum_{i=0}^{\infty} i\cdot \Pr(i) \\
           &= \sum_{i=1}^{\infty} i\cdot \Pr(i)\\
           &= \sum_{i=1}^{\infty} G(i\alpha, \gamma T).\\
    \end{align*}
  \item Para um $T$ cada vez maior, tem-se que
    \begin{equation*}
      Y(T)\; \dot{\sim}\; \text{N}\left(
        \frac{\gamma}{\alpha},
        \frac{\gamma}{\alpha^2}\right).
    \end{equation*}
  \item Considere que
    $$\frac{\gamma}{\alpha} = \exp\{\boldsymbol{x}^{\top}\beta\} \Rightarrow
    \gamma = \alpha \exp\{\boldsymbol{x}^{\top}\beta\}.$$
    Essa parametrização produz um modelo de regressão para a média
    do tempo entre eventos definida por
    $$\text{E}(\tau|\boldsymbol{x}) = \frac{\alpha}{\gamma} =
    \exp\{-\boldsymbol{x}^{\top}\beta\}.$$
  \item O modelo de regressão é para o tempo entre eventos ($\tau$)
    e não diretamente para contagem porque, a menos que
    $\alpha = 1$, não é certo que
    $\text{E}(Y_i|x_i) = [\text{E}(\tau_i|x_i)]^{-1}$.
  \item $\alpha$ é um parâmetro de dispersão, assim $\alpha > 1$ indica
  subdispersão, $\alpha = 1$ equidispersão e $\alpha < 1$ superdispersão.
  \item Em \texttt{R} temos \texttt{MRDCr::gcnt(formula, data)}.
  \end{itemize}
  
\end{frame}
%%%-------------------------------------------------------------------

%%%-------------------------------------------------------------------
\subsection{Distribuição Poisson-Tweedie}

\begin{frame}[c]
\frametitle{Distribuição Tweedie}
\begin{itemize}
\item Distribuição Tweedie (J{\o}rgensen, 1997)
\begin{equation*}
\label{distri}
f(z; \mu, \phi, p) = a(z,\phi,p) \exp\{(z\psi - k(\psi))/\phi\},
\end{equation*}
onde $\mu = \mathrm{E}(Z) = k^{\prime}(\psi)$ é a média. 
\item $\phi > 0$ e $\psi$ são os parâmetros de dispersão e canônico.
\item $k(\psi)$ é a função cumulante e $a(z,\phi, p)$ é a constante normalizadora.
\item $\mathrm{var}(Z) = \phi \mu^p$ onde $p \in (-\infty  ,0] \cup [1,\infty)$ é 
um index determinando a distribuição.
\item Casos especiais: Normal ($p=0$), Poisson ($p=1$), não-central gamma ($p=1.5$), gamma ($p=2$), normal inversa ($p=3$) and distribuições estáveis ($p > 2$).
\item Notação $Z \sim Tw_p(\mu, \phi)$.
\end{itemize}
\end{frame}
%=======================================================================

%=======================================================================
\begin{frame}[c]
\frametitle{Distribuição Poisson-Tweedie}
\begin{itemize}
\item Especificação hierárquica:
\begin{align}
\begin{split}
\label{conditional}
Y|Z &\sim P(Z) \\ 
Z &\sim Tw_p(\mu, \phi). \nonumber
\end{split}
\end{align}
\item Função de probabilidade $(p > 1)$
\begin{equation*}
f(y;\mu,\phi,p) = \int_0^\infty \frac{z^y \exp^{-z}}{y!} a(z,\phi,p) \exp\{(z\psi - k(\psi))/\phi\} dz.
\end{equation*}
\item Forma fechada está disponível apenas no caso especial - binomial negativa ($p=2$).
\item Pode ser aproximada por integração Monte Carlo e/ou integração Gauss-Laguerre.
\end{itemize}
\end{frame}
%=======================================================================

%%%-------------------------------------------------------------------
\begin{frame}[fragile]
  \frametitle{Função de probabilidade}
  \begin{itemize}
  \item Em \texttt{R} temos

<<echo=TRUE, tidy=TRUE>>=
require(tweedie)
# Integrand Poisson X Tweedie distributions
integrand <- function(x, y, mu, phi, power) {
    int = dpois(y, lambda = x)*dtweedie(x, mu = mu,
                                        phi = phi, power = power)
    return(int)
}

# Computing the pmf using Monte Carlo
dptw <- function(y, mu, phi, power, control_sample) {
    pts <- control_sample$pts
    norma <- control_sample$norma
    integral <- mean(integrand(pts, y = y, mu = mu, phi = phi,
                               power = power)/norma)
    return(integral)
}
dptw <- Vectorize(dptw, vectorize.args = "y")
@

\end{itemize}
\end{frame}
%%%-------------------------------------------------------------------


%%%-------------------------------------------------------------------
\begin{frame}[fragile]
  \frametitle{Função de probabilidade}
  \begin{itemize}
  \item Exemplo

<<echo=TRUE, tidy=TRUE>>=
set.seed(123)
pts <- rtweedie(n = 1000, mu = 10, phi = 1, power = 2)
norma <- dtweedie(pts, mu = 10, phi = 1, power = 2)
control_sample <- list("pts" = pts, "norma" = norma)
dptw(y = c(0, 5, 10, 15), mu = 10, phi = 1, power = 2,
     control_sample = control_sample)
dnbinom(x = c(0, 5, 10, 15), mu = 10, size = 1)
@

\end{itemize}
\end{frame}
%%%-------------------------------------------------------------------

%=======================================================================
\begin{frame}[c]
\frametitle{Momentos e casos especiais}
\begin{itemize}
\item Média e variância marginal são facilmente obtidos
\begin{eqnarray}
\label{marginalGaussian}
\mathrm{E}(Y) &=& \mu \nonumber    \\
\mathrm{var}(Y) &=& \mu + \phi\mu^p. \nonumber
\end{eqnarray}
\item Casos especiais: Hermite ($p=0$), Neyman-Type A ($p=1$), 
      P\'olya-Aeppli ($p=1.5$), binomial negativa $(p=2)$ e Poisson inversa-Normal ($p=3$).
\item Cuidado! - Hermite é um caso limite.
\item $p$ é um índice que distingue entre importantes distribuições.
\item Espaço paramétrico de $p$ é não trivial $p \in {0}\cup[1,\infty)$.
\item Estimação de $p$ funciona como uma seleção automática de distribuições.
\item Notação $Y \sim PTw_p(\mu, \phi)$.
\end{itemize}
\end{frame}
%=======================================================================

%%%-------------------------------------------------------------------
\begin{frame}[fragile]
\begin{figure}[h]
\includegraphics[scale=0.5]{images/PoissonTweedie.png}
\caption{Distribuição de probabilidade empírica (cinza) e função de 
probabilidade aproximada (preta) por valores do
índice de dispersão e valores do parâmetro de potência: Poisson-Tweedie.}
\label{Fig3}
\centering
\end{figure}
\end{frame}

%%%-------------------------------------------------------------------

%%%-------------------------------------------------------------------
\begin{frame}{Regressão Poisson-Tweedie}
\begin{itemize}
\item Considere $(y_i, x_i)$, $i = 1,\ldots, n$, onde $y_i$'s são iid 
realizações de $Y_i$ de acordo com a distribuição Poisson-Tweedie.
\vspace{0,5cm}
\item Modelo de regressão Poisson-Tweedie
$$Y_i \sim PTw_{p}(\mu_i, \phi), \quad  \text{sendo} \quad 
\mu_i = g^{-1}(\boldsymbol{x_i}^{\top} \boldsymbol{\beta}),$$
onde $\boldsymbol{x_i}$ and $\boldsymbol{\beta}$ são vetores $(p \times 1)$
de covariáveis conhecidas e parâmetros de regressão.
\vspace{0,5cm}
\item Em \texttt{R} temos \texttt{dptw()}.
\item $g$ função de ligação (log link).
\end{itemize}
\end{frame}

%%%-------------------------------------------------------------------
\subsection{Distribuição COM-Poisson}

\begin{frame}[allowframebreaks]{Distribuição COM-Poisson}

\begin{itemize}
    \item Nome COM-Poisson, advém de seus autores {\bf CO}nway e
    {\bf M}axwell (também é chamada de distribuição
    Conway-Maxwell-Poisson).
    \item Proposta em um contexto de filas,
    essa distribuição generaliza a Poisson com a adição de um parâmetro.
    \item Modifica a relação entre probabilidades consecutivas.
    \begin{multicols}{2}
        \begin{itemize}
            \item {\bf Distribuição Poisson}\\
            $$\frac{Pr(Y = y-1)}{Pr(Y = y)} = \frac{y}{\lambda}$$
            \item {\bf Distribuição COM-Poisson}\\
            $$\frac{Pr(Y = y-1)}{Pr(Y = y)} = \frac{y^\nu}{\lambda}$$
        \end{itemize}
    \end{multicols}   
\end{itemize}

\framebreak

\begin{block}{Distribuição de probabilidades}
\begin{center}
\begin{equation*} 
    f(y; \lambda, \nu) = \frac{\lambda^y}{(y!)^\nu 
    Z(\lambda, \nu)}, \quad \textrm{em que }\, Z(\lambda, \nu) = 
    \sum_{j=0}^\infty \frac{\lambda^j}{(j!)^\nu} \textrm{; e}\quad
    \lambda > 0, \, \nu \geq 0
\end{equation*}
\end{center}
\end{block}

\begin{block}{Casos particulares}
\begin{itemize}
	\item Distribuição Poisson, quando $\nu = 1$
	\item Distribuição Bernoulli, quando $\nu \rightarrow \infty$
	\item Distribuição Geométrica, quando $\nu = 0, \quad \lambda < 1$
\end{itemize}
\end{block}
\end{frame}

%%%-------------------------------------------------------------------
\begin{frame}{Distribuição COM-Poisson}

\begin{columns}[t]
\begin{column}{.3\textwidth}
  \vspace{1cm}
    \begin{itemize}
      \setbeamercovered{transparent=35}
      \uncover<1>{\item Poisson $\nu = 1$}
      \uncover<2>{\item Bernoulli $\nu \rightarrow \infty$}
      \uncover<3>{\item Geométrica $\nu = 0,\, \lambda < 1$}
    \end{itemize}
  \vspace{1cm}
\end{column}

\begin{column}{.7\textwidth}
  \vspace{0.5cm}
  \only<1>{
  \vspace{-1.1cm}
  
<<fig.width=7, out.width="0.9\\textwidth">>=
require(MRDCr)
require(lattice)
require(latticeExtra)
##-------------------------------------------
## Poisson
y <- 0:10
py <- dcmp(y, 5, 1, sumto = 30)
xyplot(py ~ y, type = c("h", "g"),
       lwd = 4, xlab = "y", ylab = "",
       main = expression(~"COM-Poisson"~(~lambda==5~","~nu==1)))

@
}
  \only<2>{
  \vspace{-1.1cm}
<<fig.width=7, out.width="0.9\\textwidth">>=

##-------------------------------------------
## Bernoulli
y <- 0:2
py <- dcmp(y, 3, 20, sumto = 30)
xyplot(py ~ y, type = c("h", "g"),
       lwd = 4, xlab = "y", ylab = "",
       main = expression(~"COM-Poisson"~(~lambda==3~","~nu==20)))

@
}
  \only<3>{
    \vspace{-1.1cm}
<<fig.width=7, out.width="0.9\\textwidth">>=

##-------------------------------------------
## Geometrica
y <- 0:6
py <- dcmp(y, 0.5, 0, sumto = 30)
xyplot(py ~ y, type = c("h", "g"),
       lwd = 4, xlab = "y", ylab = "",
       main = expression(~"COM-Poisson"~(~lambda==0.5~","~nu==0)))
@
}
  \end{column}
\end{columns}

\end{frame}


%%%-------------------------------------------------------------------
\begin{frame}[fragile]
\begin{figure}[h]
\includegraphics[scale=0.8]{images/COMPoisson.png}
\caption{Distribuição de probabilidade por valores do
índice de dispersão: COM-Poisson.}
\label{Fig3}
\centering
\end{figure}
\end{frame}

%%%-------------------------------------------------------------------
\begin{frame}{Assintocidade da função Z}

$$ Z(\lambda, \nu) = \sum_{j=0}^\infty \frac{\lambda^j}{(j!)^\nu} $$

<<fig.height=3, fig.width=9>>=
require(plyr)
##-------------------------------------------
## Calcula Z para um c(lambda, phi)
funZ <- function(lambda, nu, maxit = 500, tol = 1e-5) {
    z <- rep(NA, maxit)
    j = 1
    ##
    z[j] <- exp(j * log(lambda) - nu * lfactorial(j))
    ##
    while (abs(z[j] - 0) > tol && j <= maxit) {
        j = j + 1
        z[j] <- exp(j * log(lambda) - nu * lfactorial(j))
    }
    return(cbind("j" = 0:j, "z" = c(1, z[!is.na(z)])))
}

params <- list(c("lambda" = 1.36, "nu" = 0.4),
               c("lambda" = 8, "nu" = 1),
               c("lambda" = 915, "nu" = 2.5))

zs <- sapply(params, function(x) funZ(x["lambda"], x["nu"]),
           simplify = FALSE)
names(zs) <- seq_along(zs)
da <- ldply(zs)

fl <- expression(lambda == 1.36~","~nu == 0.4,
                 lambda == 8~","~nu == 1,
                 lambda == 915~","~nu == 2.5)

xyplot(z ~ j | .id, data = da,
       type = c("b", "g"), pch = 19,
       scales = "free",
       ylab = list(
           expression(frac(lambda^j, "(j!)"^nu)),
           rot = 0),
       strip = strip.custom(factor.levels = fl))

@
\end{frame}


%%%-------------------------------------------------------------------
\begin{frame}{Momentos da distribuição}

\begin{columns}[t,onlytextwidth]
\column{.48\textwidth}
Não tem expressão analítica, calculamos utilizando a definição de média e
variância;
\begin{itemize}
  \itemsep7.5pt\parskip0pt\parsep0pt
  \item $\mathrm{E}(Y) = \begin{aligned} 
            &\sum_{y = 0}^{\infty} y \cdot p(y)&
        \end{aligned}
        $
  \item $\mathrm{var}(Y) = \begin{aligned} 
            &\sum_{y = 0}^{\infty} y^2 \cdot p(y) - \mathrm{E}^2(Y)&
        \end{aligned}
        $
\end{itemize}

\column{.48\textwidth}
Aproximação proposta por Shimueli (2005), boa aproximação para $\nu 
\leq 1$ ou $\lambda > 10^\nu$ \\[0.2cm]
\begin{itemize}
  \itemsep7.5pt\parskip0pt\parsep0pt
  \item $\mathrm{E}(Y) \approx$ $\begin{aligned} 
            &\lambda ^ \frac{1}{\nu} - \frac{\nu - 1}{2\nu}&
        \end{aligned}
        $ 
  \item $\mathrm{var}(Y) \approx$ $\begin{aligned} 
            &\frac{1}{\nu}\cdot \mathrm{E}(Y)&
        \end{aligned}
        $
\end{itemize}
\end{columns}
\begin{itemize}
  \item Regressão COM-Poisson: $\lambda_i = \exp(\boldsymbol{x}_i^{\top} \boldsymbol{\beta})$, 
  em que $\boldsymbol{x}_i$ é o vetor de covariáveis do i-ésimo indivíduo e 
  $\boldsymbol{\beta}$ o vetor de parâmetros.
\end{itemize}
\end{frame}

%%%-------------------------------------------------------------------
\subsection{Comparando distribuições para contagens}
\begin{frame}{Medindo propriedades das distribuições}
\begin{itemize}

\item Índice de dispersão: $$\mathrm{DI} = \frac{\mathrm{var}(Y)}{\mathrm{E}(Y)}.$$
$ DI < 1$ subdispersão, $DI = 1$ equidispersão e $DI > 1$ superdispersão.
\vspace{0,5cm}
\item Índice de inflação de zeros: $$\mathrm{ZI} = 1 + \frac{\log \mathrm{P}(Y = 0)}{\mathrm{E}(Y)}.$$
$ZI < 0$ zero deflacionado, $ZI=1$ não zero inflacionado e $ZI > 1$ zero inflacionado.
\vspace{0,5cm}
\item Índice de cauda pesada:
$$ \mathrm{HT} = \frac{\mathrm{P}(Y=y+1)}{\mathrm{P}(Y=y)}\quad \text{for} \quad y \to \infty.$$
$\mathrm{HT} \to 1$ quando $y \to \infty$ indica cauda pesada.
\end{itemize}
\end{frame}

%%%-------------------------------------------------------------------
\begin{frame}[fragile]
\begin{figure}[h]
\includegraphics[scale=0.5]{images/Compara.png}
\caption{}
\label{Fig3}
\centering
\end{figure}
\end{frame}

%%%-------------------------------------------------------------------

%%%-------------------------------------------------------------------
\begin{frame}[fragile]
\begin{figure}[h]
\includegraphics[scale=0.6]{images/heavytail-1.png}
\caption{Índice de cauda pesada para alguns valores extremos da va $Y$.}
\label{Fig3}
\centering
\end{figure}
\end{frame}

%%%-------------------------------------------------------------------

%%%-------------------------------------------------------------------
\begin{frame}[fragile]{Flexibilidade}
\begin{table}[h]
\centering
\caption{Modelo de referência e fatos dominantes por valores dos parâmetros de dispersão e potência.}
\label{tab:model}
\begin{tabular}{llll} \hline
Modelo de referência     & Fatos dominantes                     & Dispersão           & Power   \\ \hline
Poisson                  & Equi                                 & $-$          & $-$      \\
Gamma-Count              & Sub, Equi, Super, deflação de zero   & $\alpha \lessgtr 1$ & $-$ \\
COM-Poisson              & Sub, Equi, Super, deflação de zero   & $\nu \lessgtr 1$    & $-$ \\
Hermite                  & Super                                & $\phi > 0$    & $p = 0$   \\
Neyman Type A            & Super, Zero-inflacionado             & $\phi > 0$          & $p = 1$ \\
\textit{Poisson compound Poisson} & Super, Zero-inflacionado    & $\phi > 0$ & $1 < p < 2$ \\
P\'olya-Aeppli           & Super, Zero-inflacionado             & $\phi > 0$ & $p = 1.5$ \\
Negative binomial        & Super                                & $\phi > 0$ & $p = 2$ \\
\textit{Poisson positive stable}  & Super, cauda pesada         & $\phi > 0$       & $p > 2$ \\
Poisson-inverse Gaussian & Super, cauda pesada                  & $\phi > 0$       & $p = 3$ \\ \hline
\end{tabular}
\end{table}
\end{frame}

%%%-------------------------------------------------------------------